{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Відкриття гугл диска"
      ],
      "metadata": {
        "id": "da4NGJXFep8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03oGkBwgehRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25212f0-05ea-43e0-c48b-3e03335e4f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "PzzsQ21besk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дата лоадер"
      ],
      "metadata": {
        "id": "9PtfeaoQetpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pathes(base_folder ):\n",
        "    paths = []\n",
        "    for i in range(11):\n",
        "        folder_name = f'{i:02d}'\n",
        "        image_folder = os.path.join(base_folder, folder_name, 'image_0')\n",
        "        movements_file = os.path.join(base_folder, folder_name, f'{folder_name}.txt')\n",
        "        paths.append((image_folder,movements_file))\n",
        "    return paths\n",
        "\n",
        "def get_data(batch_size, base_folder = '/content/drive/MyDrive'):\n",
        "    paths = get_pathes(base_folder)\n",
        "\n",
        "    # Вибір папок для тренування, валідації і тестування\n",
        "    validation_folder = paths[-2]  # Предостання папка\n",
        "    test_folder = paths[-1]        # Остання папка\n",
        "    train_folders = paths[:-2]     # Всі інші папки\n",
        "\n",
        "    # Читання рухання з файлу\n",
        "    def create_movements(movements_file):\n",
        "        movements = []\n",
        "        with open(movements_file, 'r') as f:\n",
        "            for line in f:\n",
        "                data = list(map(float, line.strip().split()))\n",
        "                movements.append(data)\n",
        "        return movements\n",
        "\n",
        "    # movements = create_movements(movements_file)\n",
        "\n",
        "    # Перетворення рухів\n",
        "    # def transform_mov(movements):\n",
        "    #     new_movements = []\n",
        "    #     for matrix in movements:\n",
        "    #         new_matrix = [\n",
        "    #             matrix[0:4],\n",
        "    #             matrix[4:8],\n",
        "    #             matrix[8:12],\n",
        "    #             [0, 0, 0, 1]\n",
        "    #         ]\n",
        "    #         new_matrix = torch.tensor(new_matrix, dtype=torch.float32)\n",
        "    #         new_movements.append(new_matrix)\n",
        "\n",
        "    #     res_movements = []\n",
        "    #     for i in range(len(new_movements) - 1):\n",
        "    #         T1_inv = torch.linalg.inv(new_movements[i])\n",
        "    #         T_rel = torch.matmul(new_movements[i + 1], T1_inv)\n",
        "    #         res_matrix = T_rel[:3]\n",
        "    #         res_matrix = torch.cat([res_matrix[0], res_matrix[1], res_matrix[2]])\n",
        "    #         res_movements.append(res_matrix)\n",
        "\n",
        "\n",
        "    #     return res_movements\n",
        "\n",
        "    # def transform_mov(movements):\n",
        "    #     res_movements = []\n",
        "    #     for i in range(len(movements)-1):\n",
        "    #         m1 = torch.tensor(movements[i])\n",
        "    #         m2 = torch.tensor(movements[i+1])\n",
        "    #         res = m2-m1\n",
        "    #         res_movements.append(res)\n",
        "    #     return res_movements\n",
        "    step = 1\n",
        "\n",
        "    def transform_mov(movements):\n",
        "        res_movements = []\n",
        "        # for i in range(len(movements)-1):\n",
        "        for i in range(len(movements)-step):\n",
        "            m1 = torch.tensor(movements[i])\n",
        "            m2 = torch.tensor(movements[i+step])\n",
        "            res = m2-m1\n",
        "            distance = math.sqrt(pow(res[3],2) + pow(res[7],2) + pow(res[11],2))\n",
        "            res_movements.append([distance ])\n",
        "        return res_movements\n",
        "\n",
        "\n",
        "\n",
        "    # movements = transform_mov(movements)\n",
        "\n",
        "    # класс Dataset\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_folder, movements, transform=None ):\n",
        "            # Отримуємо список всіх файлів .png і сортуємо їх\n",
        "            all_image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')])\n",
        "            self.image_files = all_image_files\n",
        "            self.movements = movements\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            # Повертаємо мінімальну довжину між рухами та зображеннями - 1\n",
        "            return min(len(self.movements), len(self.image_files) - 1)\n",
        "\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            image1_path = self.image_files[idx]\n",
        "            # image2_path = self.image_files[idx + 1]\n",
        "            image2_path = self.image_files[idx + step]\n",
        "\n",
        "            image1 = Image.open(image1_path).convert('L')\n",
        "            image2 = Image.open(image2_path).convert('L')\n",
        "\n",
        "            if self.transform:\n",
        "                image1 = self.transform(image1)\n",
        "                image2 = self.transform(image2)\n",
        "\n",
        "            movement = self.movements[idx].clone().detach().float()if isinstance(self.movements[idx], torch.Tensor) else torch.tensor(self.movements[idx], dtype=torch.float32)\n",
        "            return (image1, image2), movement\n",
        "\n",
        "\n",
        "    # Трансформації для зменшення використання пам'яті\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        # transforms.Resize((376,1240)),\n",
        "        transforms.CenterCrop((370,1226)),\n",
        "        # transforms.Resize((180,320)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    def load_dataset(folders):\n",
        "        images, movements = [], []\n",
        "        for image_folder, movements_file in folders:\n",
        "            mov = create_movements(movements_file)\n",
        "            mov = transform_mov(mov)\n",
        "            movements.append(mov)\n",
        "            images.append(image_folder)\n",
        "        return images, movements\n",
        "\n",
        "    train_images, train_movements = load_dataset(train_folders)\n",
        "    train_dataset = []\n",
        "    for index,image_folder in enumerate(train_images):\n",
        "        dataset = ImageDataset(image_folder, train_movements[index], transform=transform)\n",
        "        train_dataset.append(dataset)\n",
        "    train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n",
        "\n",
        "    # Завантаження валідаційних даних\n",
        "    val_images, val_movements = load_dataset([validation_folder])\n",
        "    val_dataset = ImageDataset(val_images[0], val_movements[0], transform=transform)\n",
        "\n",
        "\n",
        "   # Завантаження тестових даних\n",
        "    test_images, test_movements = load_dataset([test_folder])\n",
        "    test_dataset = ImageDataset(test_images[0], test_movements[0], transform=transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers=4, pin_memory=True)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader\n"
      ],
      "metadata": {
        "id": "HFQdWvw3evPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION"
      ],
      "metadata": {
        "id": "e5KxNCpLewz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def compute_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    correct_predictions = 0   # Лічильник коректних передбачень\n",
        "    total_samples = 0         # Загальна кількість елементів\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, ((feature1, feature2),targets) in enumerate(data_loader):\n",
        "            feature1 = feature1.to(device)\n",
        "            feature2 = feature2.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predicted_y = model(feature1, feature2)\n",
        "            # print(predicted_y[0].item(), '   ', targets[0].item())\n",
        "\n",
        "            # Обчислення помилки\n",
        "            loss = criterion(predicted_y, targets)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Перевірка критерію якості\n",
        "            relative_difference = torch.abs((predicted_y - targets))  # Розрахунок абсолютного відхилення\n",
        "            valid_predictions = torch.all(relative_difference <= 0.1, dim=1)    # Умова: відхилення <= 10 см\n",
        "            correct_predictions += torch.sum(valid_predictions).item()\n",
        "            total_samples = total_samples + targets.size(0)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / num_batches             # Розрахунок середньої помилки\n",
        "    accuracy = correct_predictions / total_samples  # Розрахунок частки вірних передбачень\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "JHbXDiteeyNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "jUfPohmye0RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size = (7,7), stride = (2,2), padding=(3, 3)),# 185, 613\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 185, 613\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),#93, 307\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 93, 307\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),#47, 154\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#47, 154\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(128,256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),# 24, 77\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 24, 77\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(256,512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),# 12, 39\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 12, 39\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  #  6 × 20\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  #  3 × 10\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # nn.AdaptiveAvgPool2d((5, 5))  # Глобальний пулінг до фіксованого розміру\n",
        "        )\n",
        "        self.lstm1 = nn.LSTMCell(input_size = 512 * 3 * 10, hidden_size=128)\n",
        "        self.lstm2 = nn.LSTMCell(input_size = 512 * 3 * 10, hidden_size=128)\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self,image1,image2):\n",
        "        out_features1 = self.features(image1)\n",
        "        out_features2 = self.features(image2)\n",
        "        out_features1 = torch.flatten(out_features1, 1)\n",
        "        out_features2 = torch.flatten(out_features2, 1)\n",
        "        batch_size = out_features1.size(0)\n",
        "\n",
        "        # Ініціалізуємо приховані стани та стани осередків для lstm1\n",
        "        h_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features1.device)\n",
        "        c_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features1.device)\n",
        "\n",
        "        # Пропускаємо ознаки першої картинки через lstm1 (один часовий крок)\n",
        "        h_t1_next, c_t1_next = self.lstm1(out_features1, (h_t1, c_t1))\n",
        "        h_t2_next, c_t2_next = self.lstm2(out_features2, (h_t1_next, c_t1_next))\n",
        "        out = self.network(h_t2_next) # [batch_size, 1]\n",
        "        return out\n",
        "\n",
        "\n",
        "    # def forward(self,image1,image2):\n",
        "    #     images = torch.cat((image1,image2),dim = 1)\n",
        "\n",
        "    #     out_features = self.features(images)\n",
        "    #     out_features = torch.flatten(out_features, 1)\n",
        "    #     batch_size = out_features.size(0)\n",
        "\n",
        "    #     # Ініціалізуємо приховані стани та стани осередків для lstm1\n",
        "    #     h_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "    #     c_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "\n",
        "    #     # Пропускаємо ознаки першої картинки через lstm1 (один часовий крок)\n",
        "    #     h_t1_next, c_t1_next = self.lstm1(out_features, (h_t1, c_t1))\n",
        "\n",
        "    #    # Пропускаємо ознаки першої картинки через lstm2 (один часовий крок)\n",
        "    #     h_t2_next, c_t2_next = self.lstm2(h_t1_next, (h_t1_next, c_t1_next))\n",
        "\n",
        "    #     out = self.network(h_t2_next) # [batch_size, 1]\n",
        "    #     return out"
      ],
      "metadata": {
        "id": "eo_J1uEGezmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "3dIlvrYye3JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs, last_epoch, train_loader,\n",
        "                validation_loader, test_loader,optimizer, device,scheduler,\n",
        "          checkpoint_dict):\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_loss_list, valid_loss_list = [] ,[], []\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(last_epoch, num_epochs):\n",
        "        model.train()\n",
        "        for batch_idx,((feature1,feature2),targets) in enumerate(train_loader):\n",
        "            feature1 = feature1.to(device)\n",
        "            feature2 = feature2.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predicted_y = model(feature1,feature2)\n",
        "            loss = criterion(predicted_y, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if batch_idx %100 == 0:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
        "                      f'| Loss: {loss:.4f}'\n",
        "                      f'| Learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "        # scheduler.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            avg_loss_train, accuracy_train = compute_accuracy(model, train_loader, device)\n",
        "            avg_loss_val, accuracy_val = compute_accuracy(model, validation_loader, device)\n",
        "            # scheduler.step( avg_loss_val)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train AVG LOSS: {avg_loss_train: .4f} | Accuracy_train: {accuracy_train: .4f} \\n'\n",
        "                  f'| Validation AVG LOSS: {avg_loss_val: .4f} | Accuracy_val: {accuracy_val: .4f} ')\n",
        "            train_loss_list.append(avg_loss_train)\n",
        "            valid_loss_list.append(avg_loss_val)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # checkpoint = {\n",
        "        #     'model_state_dict': model.state_dict(),\n",
        "        #     'optimizer_state_dict': optimizer.state_dict()\n",
        "        # }\n",
        "\n",
        "        checkpoint_dict['state_model'] = model.state_dict()\n",
        "        checkpoint_dict['state_opt'] =  optimizer.state_dict()\n",
        "        checkpoint_dict[ 'state_scheduler'] = scheduler.state_dict()\n",
        "        checkpoint_dict['train_loss'] = avg_loss_train\n",
        "        checkpoint_dict['val_loss'] = avg_loss_val\n",
        "        checkpoint_dict['train_acc'] = accuracy_train\n",
        "        checkpoint_dict['val_acc'] =  accuracy_val\n",
        "        checkpoint_dict['EPOCHS'] = num_epochs\n",
        "        checkpoint_dict['current_epoch'] = epoch + 1\n",
        "        checkpoint_dict[ 'learning'] = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        path = directory_path + str(epoch + 1) + '_epoch.pth'\n",
        "        torch.save(checkpoint_dict, path)\n",
        "        # path = '/content/drive/My Drive/checkpoint_model_3.pth'\n",
        "        # torch.save(checkpoint, path)\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    avg_loss_test, accuracy_test = compute_accuracy(model, test_loader,device)\n",
        "    print(f'Test AVG LOSS: {avg_loss_test: .4f} | Accuracy_test: {accuracy_test: .4f}')\n",
        "\n",
        "    return minibatch_loss_list, train_loss_list, valid_loss_list\n"
      ],
      "metadata": {
        "id": "ea_QjJiZe1qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опис моделі, оптимізатора, шедулера"
      ],
      "metadata": {
        "id": "PUhv1JcDe5hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_model_opt_shed = '''\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(2, 32, kernel_size = (7,7), stride = (2,2), padding=(3, 3)),# 185, 613\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 185, 613\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),#93, 307\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 93, 307\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),#47, 154\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#47, 154\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(128,256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),# 24, 77\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 24, 77\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(256,512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),# 12, 39\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),# 12, 39\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace = True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  #  6 × 20\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  #  3 × 10\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # nn.AdaptiveAvgPool2d((5, 5))  # Глобальний пулінг до фіксованого розміру\n",
        "        )\n",
        "        self.lstm1 = nn.LSTMCell(input_size = 512 * 3 * 10, hidden_size=128)\n",
        "        self.lstm2 = nn.LSTMCell(input_size = 128, hidden_size=128)\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    # def forward(self,image1,image2):\n",
        "    #     out_features1 = self.features(image1)\n",
        "    #     out_features2 = self.features(image2)\n",
        "    #     out_features1 = torch.flatten(out_features1, 1)\n",
        "    #     out_features2 = torch.flatten(out_features2, 1)\n",
        "    #     batch_size = out_features1.size(0)\n",
        "\n",
        "    #     # Ініціалізуємо приховані стани та стани осередків для lstm1\n",
        "    #     h_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features1.device)\n",
        "    #     c_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features1.device)\n",
        "\n",
        "    #     # Пропускаємо ознаки першої картинки через lstm1 (один часовий крок)\n",
        "    #     h_t1_next, c_t1_next = self.lstm1(out_features1, (h_t1, c_t1))\n",
        "    #     h_t2_next, c_t2_next = self.lstm2(out_features2, (h_t1_next, c_t1_next))\n",
        "    #     out = self.network(h_t2_next) # [batch_size, 1]\n",
        "    #     return out\n",
        "\n",
        "\n",
        "    def forward(self,image1,image2):\n",
        "        images = torch.cat((image1,image2),dim = 1)\n",
        "\n",
        "        out_features = self.features(images)\n",
        "        out_features = torch.flatten(out_features, 1)\n",
        "        batch_size = out_features.size(0)\n",
        "\n",
        "        # Ініціалізуємо приховані стани та стани осередків для lstm1\n",
        "        h_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "        c_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "\n",
        "        # Пропускаємо ознаки першої картинки через lstm1 (один часовий крок)\n",
        "        h_t1_next, c_t1_next = self.lstm1(out_features, (h_t1, c_t1))\n",
        "\n",
        "       # Пропускаємо ознаки першої картинки через lstm2 (один часовий крок)\n",
        "        h_t2_next, c_t2_next = self.lstm2(h_t1_next, (h_t1_next, c_t1_next))\n",
        "\n",
        "        out = self.network(h_t2_next) # [batch_size, 1]\n",
        "        return out\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.0003)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "jV_pdeV8e8wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание библиотеки для хранения сохранения"
      ],
      "metadata": {
        "id": "9oZuIlHWe-Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/drive/My Drive/checpoint/bestself_lstm_1ch/'\n",
        "\n",
        "# Перевірка існування директорії\n",
        "if not os.path.exists(directory_path):\n",
        "    # Створення директорії\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Директорія {directory_path} була створенна.\")\n",
        "else:\n",
        "    print(f\"Директорія {directory_path} вже існує.\")"
      ],
      "metadata": {
        "id": "JTfaN1Kpe_7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a8f121-a569-4c00-c281-6d7279cdf974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Директорія /content/drive/My Drive/checpoint/bestself_lstm_1ch/ була створенна.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Створення словника для збереження результатів"
      ],
      "metadata": {
        "id": "gbWHxfYRfByD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dict = {\n",
        "    'model_description' : txt_model_opt_shed,\n",
        "    'state_model' : None,\n",
        "    'state_opt'   : None,\n",
        "    'state_scheduler' : None,\n",
        "\n",
        "    'train_loss' :None,\n",
        "    'val_loss'   : None,\n",
        "    'best_loss'  : None,\n",
        "    'train_acc'  : None,\n",
        "    'val_acc'    : None,\n",
        "\n",
        "    'EPOCHS'     : None,\n",
        "    'current_epoch' : None,\n",
        "    'learning' : None\n",
        "}"
      ],
      "metadata": {
        "id": "-Qn9c-p5fDhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN"
      ],
      "metadata": {
        "id": "3JVl4xjxfFAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "RANDOM_SEED = 123\n",
        "NUM_EPOCHS = 5\n",
        "last_epoch = 0\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Використовується пристрій: {DEVICE}\")"
      ],
      "metadata": {
        "id": "8rYFolahfGGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0c1ec8-ce07-463a-dc85-9b5c309e09dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Використовується пристрій: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "set_all_seeds(RANDOM_SEED)\n",
        "\n",
        "model = Network()\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.0003)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "train_loader, validation_loader, test_loader = get_data(batch_size = BATCH_SIZE)\n",
        "# scheduler = StepLR(optimizer, step_size = 4, gamma = 0.3)\n",
        "scheduler = None\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "dF29lnrbfIiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b93e90-8c17-4358-f9ea-53bdc557e038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 25,464,289 trainable parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження словника з файлу\n",
        "path = './2_epoch.pth'\n",
        "checkpoint = torch.load(path)\n",
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "# # Завантаження стану моделі\n",
        "# save_check = checkpoint['optimizer_state_dict']\n",
        "# save_check['lr'] = 0.0003\n",
        "model.load_state_dict( checkpoint['state_model'] )\n",
        "optimizer.load_state_dict( checkpoint['state_opt'] )\n",
        "scheduler.load_state_dict( checkpoint['state_scheduler'] )\n",
        "last_epoch = checkpoint['current_epoch']\n",
        "# # Завантаження стану оптимізатора\n",
        "# optimizer.load_state_dict(save_check)"
      ],
      "metadata": {
        "id": "N-dZbzOxfOH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "minibatch_loss, train_acc, valid_acc = train(model = model,\n",
        "            num_epochs = NUM_EPOCHS,\n",
        "            last_epoch = last_epoch,\n",
        "            train_loader = train_loader,\n",
        "            validation_loader = validation_loader,\n",
        "            test_loader = test_loader,\n",
        "            optimizer = optimizer,\n",
        "            device = DEVICE,\n",
        "            scheduler = scheduler,\n",
        "            checkpoint_dict = checkpoint_dict)"
      ],
      "metadata": {
        "id": "i6CUnADlfOoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb4734a-359d-419d-b800-8b70d176abf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/005 | Batch 0000/2550 | Loss: 0.7455| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0100/2550 | Loss: 0.1454| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0200/2550 | Loss: 0.2166| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0300/2550 | Loss: 0.0735| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0400/2550 | Loss: 0.0152| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0500/2550 | Loss: 0.0451| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0600/2550 | Loss: 0.0705| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0700/2550 | Loss: 0.0245| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0800/2550 | Loss: 0.0470| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0900/2550 | Loss: 0.1075| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1000/2550 | Loss: 0.0342| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1100/2550 | Loss: 0.0073| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1200/2550 | Loss: 0.0202| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1300/2550 | Loss: 0.0143| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1400/2550 | Loss: 0.0455| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1500/2550 | Loss: 0.0481| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1600/2550 | Loss: 0.0398| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1700/2550 | Loss: 0.0169| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1800/2550 | Loss: 0.0303| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1900/2550 | Loss: 0.0316| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2000/2550 | Loss: 0.0598| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2100/2550 | Loss: 0.0407| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2200/2550 | Loss: 0.0482| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2300/2550 | Loss: 0.0482| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2400/2550 | Loss: 0.0212| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2500/2550 | Loss: 0.0135| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Train AVG LOSS:  0.0232 | Accuracy_train:  0.5255 \n",
            "| Validation AVG LOSS:  0.0735 | Accuracy_val:  0.3182 \n",
            "Time elapsed: 57.95 min\n",
            "Epoch: 002/005 | Batch 0000/2550 | Loss: 0.0255| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0100/2550 | Loss: 0.0359| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0200/2550 | Loss: 0.0192| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0300/2550 | Loss: 0.0145| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0400/2550 | Loss: 0.0315| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0500/2550 | Loss: 0.0081| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0600/2550 | Loss: 0.0115| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0700/2550 | Loss: 0.0289| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0800/2550 | Loss: 0.0077| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0900/2550 | Loss: 0.0132| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1000/2550 | Loss: 0.0303| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1100/2550 | Loss: 0.0076| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1200/2550 | Loss: 0.0176| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1300/2550 | Loss: 0.0204| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1400/2550 | Loss: 0.0149| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1500/2550 | Loss: 0.0549| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1600/2550 | Loss: 0.0121| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1700/2550 | Loss: 0.0172| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1800/2550 | Loss: 0.0137| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1900/2550 | Loss: 0.0173| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2000/2550 | Loss: 0.0074| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2100/2550 | Loss: 0.0123| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2200/2550 | Loss: 0.0236| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2300/2550 | Loss: 0.0076| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2400/2550 | Loss: 0.0389| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2500/2550 | Loss: 0.0219| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Train AVG LOSS:  0.0129 | Accuracy_train:  0.6430 \n",
            "| Validation AVG LOSS:  0.0767 | Accuracy_val:  0.2956 \n",
            "Time elapsed: 80.57 min\n",
            "Epoch: 003/005 | Batch 0000/2550 | Loss: 0.0253| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0100/2550 | Loss: 0.0117| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0200/2550 | Loss: 0.0085| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0300/2550 | Loss: 0.0219| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0400/2550 | Loss: 0.0064| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0500/2550 | Loss: 0.0073| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0600/2550 | Loss: 0.0064| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0700/2550 | Loss: 0.0116| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0800/2550 | Loss: 0.0051| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0900/2550 | Loss: 0.0118| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1000/2550 | Loss: 0.0179| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1100/2550 | Loss: 0.0043| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1200/2550 | Loss: 0.0159| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1300/2550 | Loss: 0.0142| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1400/2550 | Loss: 0.0094| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1500/2550 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1600/2550 | Loss: 0.0092| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1700/2550 | Loss: 0.0136| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1800/2550 | Loss: 0.0157| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1900/2550 | Loss: 0.0093| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2000/2550 | Loss: 0.0044| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2100/2550 | Loss: 0.0129| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2200/2550 | Loss: 0.0136| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2300/2550 | Loss: 0.0159| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2400/2550 | Loss: 0.0185| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2500/2550 | Loss: 0.0053| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Train AVG LOSS:  0.0083 | Accuracy_train:  0.7582 \n",
            "| Validation AVG LOSS:  0.0665 | Accuracy_val:  0.3176 \n",
            "Time elapsed: 103.17 min\n",
            "Epoch: 004/005 | Batch 0000/2550 | Loss: 0.0119| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0100/2550 | Loss: 0.0124| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0200/2550 | Loss: 0.0059| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0300/2550 | Loss: 0.0172| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0400/2550 | Loss: 0.0130| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0500/2550 | Loss: 0.0103| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0600/2550 | Loss: 0.0090| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0700/2550 | Loss: 0.0078| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0800/2550 | Loss: 0.0073| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0900/2550 | Loss: 0.0033| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1000/2550 | Loss: 0.0064| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1100/2550 | Loss: 0.0043| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1200/2550 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1300/2550 | Loss: 0.0072| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1400/2550 | Loss: 0.0099| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1500/2550 | Loss: 0.0120| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1600/2550 | Loss: 0.0262| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1700/2550 | Loss: 0.0145| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1800/2550 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1900/2550 | Loss: 0.1537| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2000/2550 | Loss: 0.0183| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2100/2550 | Loss: 0.0054| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2200/2550 | Loss: 0.0057| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2300/2550 | Loss: 0.0024| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2400/2550 | Loss: 0.0120| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2500/2550 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Train AVG LOSS:  0.0099 | Accuracy_train:  0.7181 \n",
            "| Validation AVG LOSS:  0.0646 | Accuracy_val:  0.3409 \n",
            "Time elapsed: 125.61 min\n",
            "Epoch: 005/005 | Batch 0000/2550 | Loss: 0.0101| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0100/2550 | Loss: 0.0046| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0200/2550 | Loss: 0.0121| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0300/2550 | Loss: 0.0094| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0400/2550 | Loss: 0.0055| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0500/2550 | Loss: 0.0155| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0600/2550 | Loss: 0.0056| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0700/2550 | Loss: 0.0063| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0800/2550 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0900/2550 | Loss: 0.0028| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1000/2550 | Loss: 0.0061| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1100/2550 | Loss: 0.0033| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1200/2550 | Loss: 0.0037| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1300/2550 | Loss: 0.0046| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1400/2550 | Loss: 0.0065| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1500/2550 | Loss: 0.0074| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1600/2550 | Loss: 0.0134| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1700/2550 | Loss: 0.0191| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1800/2550 | Loss: 0.0057| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1900/2550 | Loss: 0.0182| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2000/2550 | Loss: 0.0122| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2100/2550 | Loss: 0.0151| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2200/2550 | Loss: 0.0097| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2300/2550 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2400/2550 | Loss: 0.0089| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2500/2550 | Loss: 0.0100| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Train AVG LOSS:  0.0090 | Accuracy_train:  0.7395 \n",
            "| Validation AVG LOSS:  0.0630 | Accuracy_val:  0.3516 \n",
            "Time elapsed: 147.97 min\n",
            "Total Training Time: 147.97 min\n",
            "Test AVG LOSS:  0.1103 | Accuracy_test:  0.2825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_loss_val, accuracy_val = compute_accuracy(model, validation_loader, DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v3cEZCf86Uu",
        "outputId": "ef923d04-09e7-4736-dd12-3ecfeb8bb8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44122523069381714     0.2889880836009979\n",
            "0.6314010620117188     0.3602379560470581\n",
            "1.173960566520691     0.45316970348358154\n",
            "1.100450038909912     0.5605986714363098\n",
            "1.0535552501678467     0.6563873291015625\n",
            "1.0378566980361938     0.7622151374816895\n",
            "1.1572362184524536     0.843492865562439\n",
            "1.2384068965911865     0.928745448589325\n",
            "1.232290506362915     1.0433317422866821\n",
            "1.310836911201477     1.076290249824524\n",
            "1.171535611152649     1.0711132287979126\n",
            "1.077881932258606     1.082194447517395\n",
            "1.2542418241500854     1.113807201385498\n",
            "1.2371474504470825     1.151640772819519\n",
            "1.1208637952804565     1.1913796663284302\n",
            "1.1752381324768066     1.2265307903289795\n",
            "1.1012141704559326     1.250442624092102\n",
            "1.0784406661987305     1.2774924039840698\n",
            "1.1523863077163696     1.2363101243972778\n",
            "1.0809382200241089     1.1399396657943726\n",
            "0.7766743302345276     1.1011850833892822\n",
            "0.979907214641571     1.0649473667144775\n",
            "1.5948611497879028     0.9946592450141907\n",
            "1.070954442024231     0.91362065076828\n",
            "1.008768916130066     0.84209805727005\n",
            "1.0700689554214478     0.853054404258728\n",
            "1.3299959897994995     0.8976335525512695\n",
            "1.4395331144332886     0.9837411046028137\n",
            "1.3446139097213745     1.078423023223877\n",
            "1.4984245300292969     1.180557370185852\n",
            "1.4512641429901123     1.2738068103790283\n",
            "1.4530645608901978     1.3674328327178955\n",
            "1.3541513681411743     1.439047932624817\n",
            "1.2480530738830566     1.5038559436798096\n",
            "1.0691722631454468     1.52725088596344\n",
            "0.9178691506385803     1.5146230459213257\n",
            "1.1930630207061768     1.4162144660949707\n",
            "1.0707952976226807     1.296571135520935\n",
            "0.9381018877029419     1.2137906551361084\n",
            "1.1038672924041748     1.1165934801101685\n",
            "1.0511029958724976     1.0353550910949707\n",
            "1.1395256519317627     0.9891713857650757\n",
            "1.0411626100540161     0.9724662899971008\n",
            "0.8585689067840576     0.9571811556816101\n",
            "0.9784682393074036     0.9580559730529785\n",
            "1.013230800628662     0.9892025589942932\n",
            "1.0108821392059326     0.9924066066741943\n",
            "0.9373443722724915     0.9874991178512573\n",
            "0.7833995819091797     0.9635748863220215\n",
            "0.7590020298957825     0.9330913424491882\n",
            "1.0232040882110596     0.9546950459480286\n",
            "1.0449583530426025     0.9706258177757263\n",
            "1.0694493055343628     0.9862655401229858\n",
            "1.0331332683563232     0.9774650931358337\n",
            "1.0114953517913818     0.9870443940162659\n",
            "0.9577370882034302     1.0190446376800537\n",
            "0.8789466619491577     1.0536125898361206\n",
            "0.9420512318611145     1.091975212097168\n",
            "1.098875641822815     1.121415376663208\n",
            "1.0730623006820679     1.145129680633545\n",
            "1.051647663116455     1.1324717998504639\n",
            "1.1624919176101685     1.1109575033187866\n",
            "1.127740502357483     1.1001790761947632\n",
            "1.1914165019989014     1.0706353187561035\n",
            "1.1528918743133545     0.9552920460700989\n",
            "0.8785407543182373     0.9307203888893127\n",
            "0.7084741592407227     0.9252626895904541\n",
            "1.1891149282455444     0.9495458602905273\n",
            "1.1718581914901733     1.0196692943572998\n",
            "1.2725844383239746     1.1023344993591309\n",
            "0.9593071937561035     1.1206276416778564\n",
            "1.0228760242462158     1.1014258861541748\n",
            "1.1800198554992676     1.1030967235565186\n",
            "1.1316920518875122     1.1182793378829956\n",
            "1.1331913471221924     1.1134085655212402\n",
            "1.1660078763961792     1.087781310081482\n",
            "1.0233256816864014     1.0483461618423462\n",
            "1.0169187784194946     1.0070383548736572\n",
            "1.1946723461151123     0.9641543030738831\n",
            "1.0357905626296997     0.9337157011032104\n",
            "0.8202248811721802     0.8462860584259033\n",
            "0.7271037697792053     0.7938405871391296\n",
            "0.7652170658111572     0.7788804173469543\n",
            "0.741094708442688     0.7859811782836914\n",
            "0.5923642516136169     0.8298484086990356\n",
            "0.8552687168121338     0.8644181489944458\n",
            "0.7249813079833984     0.8778449892997742\n",
            "0.8168945908546448     0.852688193321228\n",
            "0.7139284014701843     0.884297788143158\n",
            "0.9224951267242432     0.9098249673843384\n",
            "0.8402286171913147     0.9566839337348938\n",
            "0.8210526704788208     1.0113475322723389\n",
            "0.884037435054779     1.0627992153167725\n",
            "0.6973515748977661     1.1015948057174683\n",
            "0.9436046481132507     1.1422722339630127\n",
            "0.9050905108451843     1.1874096393585205\n",
            "1.090719223022461     1.239876389503479\n",
            "0.9318287372589111     1.2906544208526611\n",
            "1.0577303171157837     1.356789231300354\n",
            "1.1755292415618896     1.402105450630188\n",
            "1.1090298891067505     1.4117333889007568\n",
            "1.1352646350860596     1.406493067741394\n",
            "1.1571459770202637     1.3871643543243408\n",
            "1.1545014381408691     1.355273723602295\n",
            "1.3453621864318848     1.2887794971466064\n",
            "1.164905071258545     1.1229417324066162\n",
            "0.9373980164527893     1.0195773839950562\n",
            "0.9157255291938782     1.0126829147338867\n",
            "0.6208636164665222     1.0225303173065186\n",
            "0.7603102326393127     1.0660415887832642\n",
            "0.5484281778335571     1.1071144342422485\n",
            "0.819571316242218     1.1456252336502075\n",
            "1.0836423635482788     1.1749494075775146\n",
            "1.0702035427093506     1.1632652282714844\n",
            "0.9624000191688538     1.0800282955169678\n",
            "0.9954054951667786     0.9359572529792786\n",
            "0.6097277998924255     0.7758418917655945\n",
            "0.645720899105072     0.7592353820800781\n",
            "0.6399616599082947     0.7329859137535095\n",
            "0.5983585715293884     0.7436825633049011\n",
            "0.6369504928588867     0.7523884773254395\n",
            "0.796422004699707     0.73097825050354\n",
            "0.7983013391494751     0.7020511031150818\n",
            "0.5864721536636353     0.7290265560150146\n",
            "0.7412533164024353     0.7620730400085449\n",
            "0.9297391772270203     0.8276559710502625\n",
            "0.9928213953971863     0.9071046113967896\n",
            "0.7795768976211548     0.979898989200592\n",
            "0.8699668645858765     1.0130672454833984\n",
            "0.8433082103729248     1.0204658508300781\n",
            "0.8343364596366882     1.0210497379302979\n",
            "0.6433017253875732     1.0022116899490356\n",
            "0.7772387862205505     1.006532073020935\n",
            "0.6548764705657959     1.0065085887908936\n",
            "0.836764395236969     0.9928660988807678\n",
            "0.8561597466468811     0.968400776386261\n",
            "0.7994922399520874     0.8642968535423279\n",
            "1.0337088108062744     0.6948617696762085\n",
            "0.44646915793418884     0.6656003594398499\n",
            "0.4612816572189331     0.6179097890853882\n",
            "0.563959002494812     0.6571576595306396\n",
            "0.6379294395446777     0.7549009919166565\n",
            "0.935520589351654     0.8766337633132935\n",
            "1.0626832246780396     0.9763674736022949\n",
            "1.0680228471755981     1.0400893688201904\n",
            "0.794035792350769     1.0670238733291626\n",
            "0.7709782719612122     1.06793212890625\n",
            "0.7918235063552856     1.08583664894104\n",
            "1.1313594579696655     1.1244714260101318\n",
            "1.2284724712371826     1.1683329343795776\n",
            "1.1595418453216553     1.2264811992645264\n",
            "0.9698448777198792     1.2693556547164917\n",
            "0.950228214263916     1.303695797920227\n",
            "0.9937066435813904     1.3286685943603516\n",
            "1.0540330410003662     1.3654357194900513\n",
            "1.0984723567962646     1.3797578811645508\n",
            "1.0404053926467896     1.4355735778808594\n",
            "1.1777167320251465     1.462519884109497\n",
            "1.1563462018966675     1.478577733039856\n",
            "1.2293434143066406     1.473512053489685\n",
            "1.2575230598449707     1.4656909704208374\n",
            "1.2059361934661865     1.4612066745758057\n",
            "0.929334819316864     1.4476218223571777\n",
            "0.9414317011833191     1.4466137886047363\n",
            "0.8905595541000366     1.4495348930358887\n",
            "0.8764245510101318     1.4531499147415161\n",
            "0.9526442885398865     1.4491714239120483\n",
            "1.0864169597625732     1.4402472972869873\n",
            "0.9515641331672668     1.4292638301849365\n",
            "0.8453635573387146     1.4300947189331055\n",
            "1.0210134983062744     1.41925847530365\n",
            "1.187956690788269     1.4336401224136353\n",
            "1.3010214567184448     1.4389435052871704\n",
            "1.0129740238189697     1.461700439453125\n",
            "1.1195296049118042     1.4682860374450684\n",
            "1.2505377531051636     1.4764968156814575\n",
            "1.2919631004333496     1.4954547882080078\n",
            "1.1653214693069458     1.494848608970642\n",
            "1.0025767087936401     1.489214301109314\n",
            "0.8920051455497742     1.4866825342178345\n",
            "1.1001298427581787     1.4886008501052856\n",
            "1.0406904220581055     1.4948533773422241\n",
            "1.103993535041809     1.4988864660263062\n",
            "1.068712830543518     1.465354323387146\n",
            "1.051283597946167     1.4150599241256714\n",
            "1.204875111579895     1.2764335870742798\n",
            "1.0495673418045044     1.078272819519043\n",
            "0.6051610112190247     0.8164787888526917\n",
            "0.6144986748695374     0.602344810962677\n",
            "0.5277907252311707     0.5345282554626465\n",
            "0.5882394909858704     0.5071482062339783\n",
            "0.6314671635627747     0.5647910833358765\n",
            "0.6605216264724731     0.6544681191444397\n",
            "0.8254758715629578     0.7351047992706299\n",
            "0.7287428379058838     0.8145571351051331\n",
            "0.7223790287971497     0.851776659488678\n",
            "0.6109637022018433     0.7786672115325928\n",
            "0.44597968459129333     0.7223871946334839\n",
            "1.2037354707717896     0.7221328616142273\n"
          ]
        }
      ]
    }
  ]
}
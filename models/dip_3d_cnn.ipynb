{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyPHVOPOJF14"
      },
      "source": [
        "Відкриття гугл диска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x0d_GduAFRHf",
        "outputId": "a48f54ad-ec62-47cd-b9ef-f50777396c21"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp '/content/drive/MyDrive/images.zip' '/content/'\n",
        "!unzip /content/images.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh45supoLXv1",
        "outputId": "b9b16390-4dc4-43ef-921f-45709772b3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.24.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.15.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug) (4.11.0.86)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.37.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.1.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug\n",
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SxdtPCEJK6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from torch.amp import autocast, GradScaler\n",
        "import torchvision.transforms.functional as TF\n",
        "# import imgaug.augmenters as iaa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMGTzoGQJMfo"
      },
      "source": [
        "Дата лоадер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2e9tPaxJMBu"
      },
      "outputs": [],
      "source": [
        "def get_pathes(base_folder ):\n",
        "    paths = []\n",
        "    for i in range(11):\n",
        "        folder_name = f'{i:02d}'\n",
        "        image_folder = os.path.join(base_folder, folder_name, 'image_0')\n",
        "        movements_file = os.path.join(base_folder, folder_name, f'{folder_name}.txt')\n",
        "        paths.append((image_folder,movements_file))\n",
        "    return paths\n",
        "\n",
        "def get_data(batch_size, base_folder = '/content/images'):\n",
        "    paths = get_pathes(base_folder)\n",
        "\n",
        "    # Вибір папок для тренування, валідації і тестування\n",
        "    validation_folder = paths[-2]  # Предостання папка\n",
        "    test_folder = paths[-1]        # Остання папка\n",
        "    train_folders = paths[:-2]     # Всі інші папки\n",
        "\n",
        "    # Читання рухання з файлу\n",
        "    def create_movements(movements_file):\n",
        "        movements = []\n",
        "        with open(movements_file, 'r') as f:\n",
        "            for line in f:\n",
        "                data = list(map(float, line.strip().split()))\n",
        "                movements.append(data)\n",
        "        return movements\n",
        "\n",
        "    step = 1\n",
        "\n",
        "    def transform_mov(movements):\n",
        "        res_movements = []\n",
        "        # for i in range(len(movements)-1):\n",
        "        for i in range(len(movements)-step):\n",
        "            m1 = torch.tensor(movements[i])\n",
        "            m2 = torch.tensor(movements[i+step])\n",
        "            res = m2-m1\n",
        "            distance = math.sqrt(pow(res[3],2) + pow(res[7],2) + pow(res[11],2))\n",
        "            res_movements.append([distance ])\n",
        "        return res_movements\n",
        "\n",
        "     # класс Dataset\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_folder, movements, transform=None ):\n",
        "            # Отримуємо список всіх файлів .png і сортуємо їх\n",
        "            all_image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')])\n",
        "            self.image_files = all_image_files\n",
        "            self.movements = movements\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            # Повертаємо мінімальну довжину між рухами та зображеннями - 1\n",
        "            return min(len(self.movements), len(self.image_files) - 5)\n",
        "\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            pathes = self.image_files[idx: idx + 5*step :step]\n",
        "            images = [Image.open(p).convert('L') for p in pathes]\n",
        "\n",
        "\n",
        "            # if self.transform:\n",
        "            #     image1, image2 = self.transform(image1, image2)\n",
        "            #     image1 = transforms.ToTensor()(image1)\n",
        "            #     image2 = transforms.ToTensor()(image2)\n",
        "            if self.transform:\n",
        "                images = [self.transform(img) for img in images]\n",
        "\n",
        "            # if self.transform:\n",
        "            #     image1,image2 = self.transform(image1,image2)\n",
        "            images = torch.stack(images, dim=0)  # [5, 1, H, W]\n",
        "            images = images.permute(1, 0, 2, 3)  # [1, 5, H, W]\n",
        "            movement = self.movements[idx + 4*step].clone().float() if isinstance(self.movements[idx+ 4*step], torch.Tensor) else torch.tensor(self.movements[idx + 4*step], dtype=torch.float32)\n",
        "            return images, movement\n",
        "\n",
        "\n",
        "    # Трансформації для зменшення використання пам'яті\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        # transforms.Resize((376,1240)),\n",
        "        # transforms.CenterCrop((370,1226)),\n",
        "        transforms.Resize((180,320)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # transform = PairTransform()\n",
        "\n",
        "    def load_dataset(folders):\n",
        "        images, movements = [], []\n",
        "        for image_folder, movements_file in folders:\n",
        "            mov = create_movements(movements_file)\n",
        "            mov = transform_mov(mov)\n",
        "            movements.append(mov)\n",
        "            images.append(image_folder)\n",
        "        return images, movements\n",
        "\n",
        "    train_images, train_movements = load_dataset(train_folders)\n",
        "    train_dataset = []\n",
        "    for index,image_folder in enumerate(train_images):\n",
        "        dataset = ImageDataset(image_folder, train_movements[index], transform=transform)\n",
        "        train_dataset.append(dataset)\n",
        "    train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n",
        "\n",
        "    # Завантаження валідаційних даних\n",
        "    val_images, val_movements = load_dataset([validation_folder])\n",
        "    val_dataset = ImageDataset(val_images[0], val_movements[0], transform=transform)\n",
        "\n",
        "\n",
        "   # Завантаження тестових даних\n",
        "    test_images, test_movements = load_dataset([test_folder])\n",
        "    test_dataset = ImageDataset(test_images[0], test_movements[0], transform=transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers=4, pin_memory=True)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b-omipcJO-t"
      },
      "source": [
        "EVALUATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVj3ME_4JQdS"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def compute_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    correct_predictions = 0   # Лічильник коректних передбачень\n",
        "    total_samples = 0         # Загальна кількість елементів\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, ((feature1, feature2),targets) in enumerate(data_loader):\n",
        "            feature1 = feature1.to(device)\n",
        "            feature2 = feature2.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with autocast(device_type='cuda'):\n",
        "                predicted_y = model(feature1, feature2)\n",
        "\n",
        "            # Обчислення помилки\n",
        "            loss = criterion(predicted_y, targets)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Перевірка критерію якості\n",
        "            relative_difference = torch.abs((predicted_y - targets)) # Розрахунок абсолютного відхилення\n",
        "            valid_predictions = torch.all(relative_difference <= 0.1, dim=1)    # Умова: відхилення <= 10 см\n",
        "            correct_predictions += torch.sum(valid_predictions).item()\n",
        "            total_samples = total_samples + targets.size(0)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / num_batches             # Розрахунок середньої помилки\n",
        "    accuracy = correct_predictions / total_samples  # Розрахунок частки вірних передбачень\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def compute_accuracy1(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    correct_predictions = 0   # Лічильник коректних передбачень\n",
        "    total_samples = 0         # Загальна кількість елементів\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images,targets) in enumerate(data_loader):\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            with autocast(device_type='cuda'):\n",
        "                predicted_y = model(images)\n",
        "\n",
        "            # Обчислення помилки\n",
        "            loss = criterion(predicted_y, targets)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Перевірка критерію якості\n",
        "            relative_difference = torch.abs((predicted_y - targets)) # Розрахунок абсолютного відхилення\n",
        "            valid_predictions = torch.all(relative_difference <= 0.1, dim=1)    # Умова: відхилення <= 10 см\n",
        "            correct_predictions += torch.sum(valid_predictions).item()\n",
        "            total_samples = total_samples + targets.size(0)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / num_batches             # Розрахунок середньої помилки\n",
        "    accuracy = correct_predictions / total_samples  # Розрахунок частки вірних передбачень\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSs02KT2JR90"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq9jFuiiJp-a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcYFIAWsJTHI"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Завантажуємо переднавчену модель ResNet50\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "        base_model = resnet50(weights=weights)\n",
        "\n",
        "        # Міняжмо перший conv слой для 1-канального зображенняЗ\n",
        "        self.backbone = nn.Sequential()\n",
        "        conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        # Копіюємо та усереднюємо ваги по каналам\n",
        "        with torch.no_grad():\n",
        "            conv1.weight[:] = base_model.conv1.weight.mean(dim=1, keepdim=True)\n",
        "        self.backbone.add_module(\"conv1\", conv1)\n",
        "\n",
        "        #Додаємо інші блоки ResNet до avgpool (виключая fc)\n",
        "        for name, module in list(base_model.named_children())[1:-2]:\n",
        "            self.backbone.add_module(name, module)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 3))\n",
        "        self.lstm = nn.LSTM(input_size=2048 * 3, hidden_size=128, num_layers=1, batch_first=True)\n",
        "\n",
        "        self.classifier = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "    def forward(self,images):# images: [B, 5, 1, H, W]\n",
        "        B,T,C,H,W = images.shape\n",
        "        pairs = []\n",
        "        for t in range(1, T):\n",
        "            pair = torch.cat((images[:, t-1], images[:, t]), dim=1)  # [B, 2, H, W]\n",
        "            features = self.backbone(pair)  # [B, 2048, H', W']\n",
        "            features = self.pool(features)  # [B, 2048, 1, 3]\n",
        "            features = features.view(B, -1)  # [B, 2048 * 3]\n",
        "            pairs.append(features)\n",
        "\n",
        "        seq = torch.stack(pairs, dim=1)  # [B, 4, 2048*3]\n",
        "\n",
        "        lstm_out, _ = self.lstm(seq)  # [B, 4, 128]\n",
        "        last_output = lstm_out[:, -1, :]  # [B, 128]\n",
        "        out = self.classifier(last_output)  # [B, 1]\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNf3lK97xvYG"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Завантажуємо переднавчену модель ResNet50\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "        base_model = resnet50(weights=weights)\n",
        "\n",
        "        # Міняжмо перший conv слой для 1-канального зображенняЗ\n",
        "        self.backbone = nn.Sequential()\n",
        "        conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        # Копіюємо та усереднюємо ваги по каналам\n",
        "        with torch.no_grad():\n",
        "            conv1.weight[:] = base_model.conv1.weight.mean(dim=1, keepdim=True)\n",
        "        self.backbone.add_module(\"conv1\", conv1)\n",
        "\n",
        "        #Додаємо інші блоки ResNet до avgpool (виключая fc)\n",
        "        for name, module in list(base_model.named_children())[1:-2]:\n",
        "            self.backbone.add_module(name, module)\n",
        "\n",
        "        self.lstm1 = nn.LSTMCell(input_size = 2048*1*3, hidden_size=128)\n",
        "        self.lstm2 = nn.LSTMCell(input_size = 128, hidden_size=128)\n",
        "\n",
        "        self.classifier = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "    def forward(self,image1,image2):\n",
        "          images = torch.cat((image1,image2),dim = 1)\n",
        "\n",
        "          out_features = self.backbone(images)\n",
        "          out_features = torch.nn.functional.adaptive_avg_pool2d(out_features, (1,3 ))  # [B, C, 3, 10]\n",
        "          out_features = out_features.view(out_features.size(0), -1)  # [B, C * 3 * 10]\n",
        "\n",
        "        #   out_features = torch.flatten(out_features, 1)\n",
        "          batch_size = out_features.size(0)\n",
        "\n",
        "          # Ініціалізуємо приховані стани та стани осередків для lstm1\n",
        "          h_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "          c_t1 = torch.zeros(batch_size, self.lstm1.hidden_size, device=out_features.device)\n",
        "\n",
        "          # Пропускаємо ознаки першої картинки через lstm1 (один часовий крок)\n",
        "          h_t1_next, c_t1_next = self.lstm1(out_features, (h_t1, c_t1))\n",
        "\n",
        "        # Пропускаємо ознаки першої картинки через lstm2 (один часовий крок)\n",
        "          h_t2_next, c_t2_next = self.lstm2(h_t1_next, (h_t1_next, c_t1_next))\n",
        "\n",
        "          out = self.classifier(h_t2_next) # [batch_size, 1]\n",
        "          return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXmgFM46sA9z"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(0, 2, 2))\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, 5, 180, 320)\n",
        "            out = self._forward_conv(dummy)\n",
        "            self.flatten_size = out.view(1, -1).shape[1]\n",
        "        # Output size after convs: (B, 64, 1, 46, 153)\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)  # [x, y, z, roll, pitch, yaw]\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward_conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahE9c2jNJU0m"
      },
      "source": [
        "Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpkTwGZXJWQb"
      },
      "outputs": [],
      "source": [
        "def train(model, num_epochs, last_epoch, train_loader,\n",
        "                validation_loader, test_loader,optimizer, device,scheduler,\n",
        "          checkpoint_dict,scaler):\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_loss_list, valid_loss_list = [] ,[], []\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(last_epoch, num_epochs):\n",
        "        model.train()\n",
        "        for batch_idx,(images,targets) in enumerate(train_loader):\n",
        "            # feature1 = feature1.to(device)\n",
        "            # feature2 = feature2.to(device)\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # <<< Mixed precision begins\n",
        "            with autocast(device_type='cuda'):\n",
        "                predicted_y = model(images)\n",
        "                loss = criterion(predicted_y, targets)\n",
        "\n",
        "            #  Зворотній прохід\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if batch_idx %100 == 0:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
        "                      f'| Loss: {loss:.4f}'\n",
        "                      f'| Learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "        # scheduler.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            avg_loss_train, accuracy_train = compute_accuracy1(model, train_loader, device)\n",
        "            avg_loss_val, accuracy_val = compute_accuracy1(model, validation_loader, device)\n",
        "            # scheduler.step( avg_loss_val)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train AVG LOSS: {avg_loss_train: .4f} | Accuracy_train: {accuracy_train: .4f} \\n'\n",
        "                  f'| Validation AVG LOSS: {avg_loss_val: .4f} | Accuracy_val: {accuracy_val: .4f} ')\n",
        "            train_loss_list.append(avg_loss_train)\n",
        "            valid_loss_list.append(avg_loss_val)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # checkpoint = {\n",
        "        #     'model_state_dict': model.state_dict(),\n",
        "        #     'optimizer_state_dict': optimizer.state_dict()\n",
        "        # }\n",
        "\n",
        "        checkpoint_dict['state_model'] = model.state_dict()\n",
        "        checkpoint_dict['state_opt'] =  optimizer.state_dict()\n",
        "        checkpoint_dict[ 'state_scheduler'] = scheduler.state_dict()\n",
        "        checkpoint_dict['train_loss'] = avg_loss_train\n",
        "        checkpoint_dict['val_loss'] = avg_loss_val\n",
        "        checkpoint_dict['train_acc'] = accuracy_train\n",
        "        checkpoint_dict['val_acc'] =  accuracy_val\n",
        "        checkpoint_dict['EPOCHS'] = num_epochs\n",
        "        checkpoint_dict['current_epoch'] = epoch + 1\n",
        "        checkpoint_dict[ 'learning'] = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        path = directory_path + str(epoch + 1) + '_epoch.pth'\n",
        "        torch.save(checkpoint_dict, path)\n",
        "        # path = '/content/drive/My Drive/checkpoint_model_3.pth'\n",
        "        # torch.save(checkpoint, path)\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    avg_loss_test, accuracy_test = compute_accuracy1(model, test_loader,device)\n",
        "    print(f'Test AVG LOSS: {avg_loss_test: .4f} | Accuracy_test: {accuracy_test: .4f}')\n",
        "\n",
        "    return minibatch_loss_list, train_loss_list, valid_loss_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raMr_qAwJYVf"
      },
      "source": [
        "Опис моделі, оптимізатора, шедулера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PFsUtvsJYy5"
      },
      "outputs": [],
      "source": [
        "txt_model_opt_shed = '''\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(0, 2, 2))\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, 5, 180, 320)\n",
        "            out = self._forward_conv(dummy)\n",
        "            self.flatten_size = out.view(1, -1).shape[1]\n",
        "        # Output size after convs: (B, 64, 1, 46, 153)\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)  # [x, y, z, roll, pitch, yaw]\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward_conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir_n43vuJaVI"
      },
      "source": [
        "Створення бібліотеки для збеження збережень"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVB-P3TrJbii",
        "outputId": "bfcf0b18-6fe7-44c9-d476-fcd2e5d7d9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Директорія /content/drive/My Drive/checpoint/3dcnn/ була створенна.\n"
          ]
        }
      ],
      "source": [
        "directory_path = '/content/drive/My Drive/checpoint/3dcnn/'\n",
        "\n",
        "# Перевірка існування директорії\n",
        "if not os.path.exists(directory_path):\n",
        "    # Створення директорії\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Директорія {directory_path} була створенна.\")\n",
        "else:\n",
        "    print(f\"Директорія {directory_path} вже існує.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-_OiYpyJeNm"
      },
      "source": [
        "Створення словника для збереження результатів"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHDZ5Kb0Je4B"
      },
      "outputs": [],
      "source": [
        "checkpoint_dict = {\n",
        "    'model_description' : txt_model_opt_shed,\n",
        "    'state_model' : None,\n",
        "    'state_opt'   : None,\n",
        "    'state_scheduler' : None,\n",
        "\n",
        "    'train_loss' :None,\n",
        "    'val_loss'   : None,\n",
        "    'best_loss'  : None,\n",
        "    'train_acc'  : None,\n",
        "    'val_acc'    : None,\n",
        "\n",
        "    'EPOCHS'     : None,\n",
        "    'current_epoch' : None,\n",
        "    'learning' : None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8t-SugcJf95"
      },
      "source": [
        "MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwRoiJbpJhB3",
        "outputId": "6b78bcc1-1e0d-4c4b-debe-5d6a7be3c56a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Використовується пристрій: cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "RANDOM_SEED = 123\n",
        "NUM_EPOCHS = 5\n",
        "last_epoch = 0\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Використовується пристрій: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IkbrudJJiPW",
        "outputId": "13451687-ca75-483e-9b5c-b4b21d2dee3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 90,465,057 trainable parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "set_all_seeds(RANDOM_SEED)\n",
        "\n",
        "model = Network()\n",
        "model = model.to(DEVICE)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.0006)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "train_loader, validation_loader, test_loader = get_data(batch_size = BATCH_SIZE)\n",
        "# scheduler = StepLR(optimizer, step_size = 4, gamma = 0.3)\n",
        "scheduler = None\n",
        "scaler = GradScaler()\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITnSX-_tJkFn"
      },
      "outputs": [],
      "source": [
        "# Завантаження словника з файлу\n",
        "path = './3_epoch.pth'\n",
        "checkpoint = torch.load(path)\n",
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "# # Завантаження стану моделі\n",
        "# save_check = checkpoint['optimizer_state_dict']\n",
        "# save_check['lr'] = 0.0003\n",
        "model.load_state_dict( checkpoint['state_model'] )\n",
        "optimizer.load_state_dict( checkpoint['state_opt'] )\n",
        "scheduler.load_state_dict( checkpoint['state_scheduler'] )\n",
        "last_epoch = checkpoint['current_epoch']\n",
        "# # Завантаження стану оптимізатора\n",
        "# optimizer.load_state_dict(save_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz4GNVjjwpRR",
        "outputId": "ca53dbd2-6ee6-451a-9639-7b1e5679ea49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test AVG LOSS:  0.0524 | Accuracy_test:  0.4565\n"
          ]
        }
      ],
      "source": [
        "avg_loss_test, accuracy_test = compute_accuracy1(model, test_loader,DEVICE)\n",
        "print(f'Test AVG LOSS: {avg_loss_test: .4f} | Accuracy_test: {accuracy_test: .4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qmlbAL0Jknw",
        "outputId": "9efdd959-239f-4933-ada5-6fbdf8a05a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/005 | Batch 0000/2546 | Loss: 1.0446| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0100/2546 | Loss: 0.2923| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0200/2546 | Loss: 0.1982| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0300/2546 | Loss: 0.1440| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0400/2546 | Loss: 0.0769| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0500/2546 | Loss: 0.0596| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0600/2546 | Loss: 0.0659| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0700/2546 | Loss: 0.0325| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0800/2546 | Loss: 0.2019| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 0900/2546 | Loss: 0.0363| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1000/2546 | Loss: 0.0186| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1100/2546 | Loss: 0.0248| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1200/2546 | Loss: 0.0652| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1300/2546 | Loss: 0.0131| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1400/2546 | Loss: 0.0236| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1500/2546 | Loss: 0.0337| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1600/2546 | Loss: 0.0435| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1700/2546 | Loss: 0.0571| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1800/2546 | Loss: 0.0536| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 1900/2546 | Loss: 0.0240| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2000/2546 | Loss: 0.0756| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2100/2546 | Loss: 0.0662| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2200/2546 | Loss: 0.0081| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2300/2546 | Loss: 0.0285| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2400/2546 | Loss: 0.0271| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Batch 2500/2546 | Loss: 0.0165| Learning rate: 0.0001\n",
            "Epoch: 001/005 | Train AVG LOSS:  0.0164 | Accuracy_train:  0.5964 \n",
            "| Validation AVG LOSS:  0.0597 | Accuracy_val:  0.3329 \n",
            "Time elapsed: 18.47 min\n",
            "Epoch: 002/005 | Batch 0000/2546 | Loss: 0.0187| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0100/2546 | Loss: 0.0152| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0200/2546 | Loss: 0.0202| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0300/2546 | Loss: 0.0145| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0400/2546 | Loss: 0.0225| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0500/2546 | Loss: 0.0291| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0600/2546 | Loss: 0.0200| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0700/2546 | Loss: 0.0190| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0800/2546 | Loss: 0.0095| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 0900/2546 | Loss: 0.0115| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1000/2546 | Loss: 0.0100| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1100/2546 | Loss: 0.0096| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1200/2546 | Loss: 0.0051| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1300/2546 | Loss: 0.0199| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1400/2546 | Loss: 0.0166| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1500/2546 | Loss: 0.0078| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1600/2546 | Loss: 0.0100| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1700/2546 | Loss: 0.0100| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1800/2546 | Loss: 0.0147| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 1900/2546 | Loss: 0.0043| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2000/2546 | Loss: 0.0038| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2100/2546 | Loss: 0.0133| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2200/2546 | Loss: 0.0030| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2300/2546 | Loss: 0.0064| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2400/2546 | Loss: 0.0061| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Batch 2500/2546 | Loss: 0.0137| Learning rate: 0.0001\n",
            "Epoch: 002/005 | Train AVG LOSS:  0.0050 | Accuracy_train:  0.8528 \n",
            "| Validation AVG LOSS:  0.0570 | Accuracy_val:  0.3285 \n",
            "Time elapsed: 37.25 min\n",
            "Epoch: 003/005 | Batch 0000/2546 | Loss: 0.0069| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0100/2546 | Loss: 0.0042| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0200/2546 | Loss: 0.0055| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0300/2546 | Loss: 0.0135| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0400/2546 | Loss: 0.0086| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0500/2546 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0600/2546 | Loss: 0.0026| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0700/2546 | Loss: 0.0041| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0800/2546 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 0900/2546 | Loss: 0.0057| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1000/2546 | Loss: 0.0075| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1100/2546 | Loss: 0.0050| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1200/2546 | Loss: 0.0074| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1300/2546 | Loss: 0.0029| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1400/2546 | Loss: 0.0085| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1500/2546 | Loss: 0.0230| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1600/2546 | Loss: 0.0033| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1700/2546 | Loss: 0.0059| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1800/2546 | Loss: 0.0092| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 1900/2546 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2000/2546 | Loss: 0.0067| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2100/2546 | Loss: 0.0041| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2200/2546 | Loss: 0.0082| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2300/2546 | Loss: 0.0049| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2400/2546 | Loss: 0.0041| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Batch 2500/2546 | Loss: 0.0048| Learning rate: 0.0001\n",
            "Epoch: 003/005 | Train AVG LOSS:  0.0030 | Accuracy_train:  0.9354 \n",
            "| Validation AVG LOSS:  0.0481 | Accuracy_val:  0.3354 \n",
            "Time elapsed: 55.74 min\n",
            "Epoch: 004/005 | Batch 0000/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0100/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0200/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0300/2546 | Loss: 0.0038| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0400/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0500/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0600/2546 | Loss: 0.0019| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0700/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0800/2546 | Loss: 0.0051| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0900/2546 | Loss: 0.0062| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1000/2546 | Loss: 0.0054| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1100/2546 | Loss: 0.0078| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1200/2546 | Loss: 0.0053| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1300/2546 | Loss: 0.0029| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1400/2546 | Loss: 0.0021| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1500/2546 | Loss: 0.0029| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1600/2546 | Loss: 0.0037| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1700/2546 | Loss: 0.0020| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1800/2546 | Loss: 0.0028| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1900/2546 | Loss: 0.0024| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2000/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2100/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2200/2546 | Loss: 0.0090| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2300/2546 | Loss: 0.0015| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2400/2546 | Loss: 0.0020| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2500/2546 | Loss: 0.0078| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Train AVG LOSS:  0.0026 | Accuracy_train:  0.9541 \n",
            "| Validation AVG LOSS:  0.0492 | Accuracy_val:  0.3714 \n",
            "Time elapsed: 74.03 min\n",
            "Epoch: 005/005 | Batch 0000/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0100/2546 | Loss: 0.0066| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0200/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0300/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0400/2546 | Loss: 0.0047| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0500/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0600/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0700/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0800/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0900/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1000/2546 | Loss: 0.0042| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1100/2546 | Loss: 0.0033| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1200/2546 | Loss: 0.0015| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1300/2546 | Loss: 0.0085| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1400/2546 | Loss: 0.0030| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1500/2546 | Loss: 0.0026| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1600/2546 | Loss: 0.0054| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1700/2546 | Loss: 0.0006| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1800/2546 | Loss: 0.0026| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1900/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2000/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2100/2546 | Loss: 0.0030| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2200/2546 | Loss: 0.0035| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2300/2546 | Loss: 0.0037| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2400/2546 | Loss: 0.0015| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2500/2546 | Loss: 0.0019| Learning rate: 0.0001\n"
          ]
        }
      ],
      "source": [
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "minibatch_loss, train_acc, valid_acc = train(model = model,\n",
        "            num_epochs = NUM_EPOCHS,\n",
        "            last_epoch = last_epoch,\n",
        "            train_loader = train_loader,\n",
        "            validation_loader = validation_loader,\n",
        "            test_loader = test_loader,\n",
        "            optimizer = optimizer,\n",
        "            device = DEVICE,\n",
        "            scheduler = scheduler,\n",
        "            checkpoint_dict = checkpoint_dict,\n",
        "            scaler = scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ang3dIydNGbA",
        "outputId": "9c61c12f-b6db-4933-e9e5-2eb85a9c575c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004/005 | Batch 0000/2546 | Loss: 0.0029| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0100/2546 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0200/2546 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0300/2546 | Loss: 0.0015| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0400/2546 | Loss: 0.0056| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0500/2546 | Loss: 0.0015| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0600/2546 | Loss: 0.0021| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0700/2546 | Loss: 0.0072| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0800/2546 | Loss: 0.0046| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 0900/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1000/2546 | Loss: 0.0042| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1100/2546 | Loss: 0.0043| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1200/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1300/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1400/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1500/2546 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1600/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1700/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1800/2546 | Loss: 0.0024| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 1900/2546 | Loss: 0.0027| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2000/2546 | Loss: 0.0033| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2100/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2200/2546 | Loss: 0.0027| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2300/2546 | Loss: 0.0020| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2400/2546 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Batch 2500/2546 | Loss: 0.0006| Learning rate: 0.0001\n",
            "Epoch: 004/005 | Train AVG LOSS:  0.0024 | Accuracy_train:  0.9536 \n",
            "| Validation AVG LOSS:  0.0547 | Accuracy_val:  0.3493 \n",
            "Time elapsed: 18.21 min\n",
            "Epoch: 005/005 | Batch 0000/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0100/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0200/2546 | Loss: 0.0006| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0300/2546 | Loss: 0.0046| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0400/2546 | Loss: 0.0098| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0500/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0600/2546 | Loss: 0.0009| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0700/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0800/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 0900/2546 | Loss: 0.0085| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1000/2546 | Loss: 0.0026| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1100/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1200/2546 | Loss: 0.0027| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1300/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1400/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1500/2546 | Loss: 0.0062| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1600/2546 | Loss: 0.0021| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1700/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1800/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 1900/2546 | Loss: 0.0023| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2000/2546 | Loss: 0.0025| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2100/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2200/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2300/2546 | Loss: 0.0025| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2400/2546 | Loss: 0.0027| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Batch 2500/2546 | Loss: 0.0029| Learning rate: 0.0001\n",
            "Epoch: 005/005 | Train AVG LOSS:  0.0027 | Accuracy_train:  0.9479 \n",
            "| Validation AVG LOSS:  0.0484 | Accuracy_val:  0.3682 \n",
            "Time elapsed: 36.36 min\n",
            "Total Training Time: 36.36 min\n",
            "Test AVG LOSS:  0.0833 | Accuracy_test:  0.3236\n"
          ]
        }
      ],
      "source": [
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "minibatch_loss, train_acc, valid_acc = train(model = model,\n",
        "            num_epochs = NUM_EPOCHS,\n",
        "            last_epoch = 3,\n",
        "            train_loader = train_loader,\n",
        "            validation_loader = validation_loader,\n",
        "            test_loader = test_loader,\n",
        "            optimizer = optimizer,\n",
        "            device = DEVICE,\n",
        "            scheduler = scheduler,\n",
        "            checkpoint_dict = checkpoint_dict,\n",
        "            scaler = scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsl2cWzQZzQK",
        "outputId": "5f7f1158-59e7-4735-b6e9-4536758b39ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006/008 | Batch 0000/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0100/2546 | Loss: 0.0037| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0200/2546 | Loss: 0.0009| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0300/2546 | Loss: 0.0005| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0400/2546 | Loss: 0.0009| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0500/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0600/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0700/2546 | Loss: 0.0008| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0800/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 0900/2546 | Loss: 0.0019| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1000/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1100/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1200/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1300/2546 | Loss: 0.0080| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1400/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1500/2546 | Loss: 0.0008| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1600/2546 | Loss: 0.0027| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1700/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1800/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 1900/2546 | Loss: 0.0028| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2000/2546 | Loss: 0.0009| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2100/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2200/2546 | Loss: 0.0036| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2300/2546 | Loss: 0.0034| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2400/2546 | Loss: 0.0008| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Batch 2500/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 006/008 | Train AVG LOSS:  0.0018 | Accuracy_train:  0.9703 \n",
            "| Validation AVG LOSS:  0.0500 | Accuracy_val:  0.3632 \n",
            "Time elapsed: 18.17 min\n",
            "Epoch: 007/008 | Batch 0000/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0100/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0200/2546 | Loss: 0.0009| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0300/2546 | Loss: 0.0060| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0400/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0500/2546 | Loss: 0.0039| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0600/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0700/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0800/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 0900/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1000/2546 | Loss: 0.0013| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1100/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1200/2546 | Loss: 0.0041| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1300/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1400/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1500/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1600/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1700/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1800/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 1900/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2000/2546 | Loss: 0.0022| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2100/2546 | Loss: 0.0019| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2200/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2300/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2400/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Batch 2500/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 007/008 | Train AVG LOSS:  0.0024 | Accuracy_train:  0.9639 \n",
            "| Validation AVG LOSS:  0.0465 | Accuracy_val:  0.3676 \n",
            "Time elapsed: 36.41 min\n",
            "Epoch: 008/008 | Batch 0000/2546 | Loss: 0.0035| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0100/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0200/2546 | Loss: 0.0030| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0300/2546 | Loss: 0.0025| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0400/2546 | Loss: 0.0017| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0500/2546 | Loss: 0.0057| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0600/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0700/2546 | Loss: 0.0006| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0800/2546 | Loss: 0.0004| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 0900/2546 | Loss: 0.0028| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1000/2546 | Loss: 0.0010| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1100/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1200/2546 | Loss: 0.0007| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1300/2546 | Loss: 0.0014| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1400/2546 | Loss: 0.0005| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1500/2546 | Loss: 0.0019| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1600/2546 | Loss: 0.0031| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1700/2546 | Loss: 0.0003| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1800/2546 | Loss: 0.0012| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 1900/2546 | Loss: 0.0011| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2000/2546 | Loss: 0.0018| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2100/2546 | Loss: 0.0005| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2200/2546 | Loss: 0.0006| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2300/2546 | Loss: 0.0032| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2400/2546 | Loss: 0.0016| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Batch 2500/2546 | Loss: 0.0020| Learning rate: 0.0001\n",
            "Epoch: 008/008 | Train AVG LOSS:  0.0012 | Accuracy_train:  0.9878 \n",
            "| Validation AVG LOSS:  0.0506 | Accuracy_val:  0.3544 \n",
            "Time elapsed: 54.71 min\n",
            "Total Training Time: 54.71 min\n",
            "Test AVG LOSS:  0.0776 | Accuracy_test:  0.3353\n"
          ]
        }
      ],
      "source": [
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "minibatch_loss, train_acc, valid_acc = train(model = model,\n",
        "            num_epochs = 8,\n",
        "            last_epoch = 5,\n",
        "            train_loader = train_loader,\n",
        "            validation_loader = validation_loader,\n",
        "            test_loader = test_loader,\n",
        "            optimizer = optimizer,\n",
        "            device = DEVICE,\n",
        "            scheduler = scheduler,\n",
        "            checkpoint_dict = checkpoint_dict,\n",
        "            scaler = scaler)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

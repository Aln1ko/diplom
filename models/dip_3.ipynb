{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Открытие гугл диска"
      ],
      "metadata": {
        "id": "64fNZD5RJnnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MahOitdIJjEG",
        "outputId": "7e4e22c7-b1e4-4a34-812b-4aa88978feac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "MZLkcmKIJucP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дата лоадер"
      ],
      "metadata": {
        "id": "3FcAmWksJwIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pathes(base_folder ):\n",
        "    paths = []\n",
        "    for i in range(11):\n",
        "        folder_name = f'{i:02d}'\n",
        "        image_folder = os.path.join(base_folder, folder_name, 'image_0')\n",
        "        movements_file = os.path.join(base_folder, folder_name, f'{folder_name}.txt')\n",
        "        paths.append((image_folder,movements_file))\n",
        "    return paths\n",
        "\n",
        "def get_data(batch_size, base_folder = '/content/drive/MyDrive'):\n",
        "    paths = get_pathes(base_folder)\n",
        "\n",
        "    # Выбор папок для тренировочных, валидационных и тестовых данных\n",
        "    validation_folder = paths[-2]  # Предпоследняя папка\n",
        "    test_folder = paths[-1]        # Последняя папка\n",
        "    train_folders = paths[:-2]     # Все остальные папки\n",
        "\n",
        "    # Чтение движений из файла\n",
        "    def create_movements(movements_file):\n",
        "        movements = []\n",
        "        with open(movements_file, 'r') as f:\n",
        "            for line in f:\n",
        "                data = list(map(float, line.strip().split()))\n",
        "                movements.append(data)\n",
        "        return movements\n",
        "\n",
        "    # movements = create_movements(movements_file)\n",
        "\n",
        "    # Преобразование движений\n",
        "    # def transform_mov(movements):\n",
        "    #     new_movements = []\n",
        "    #     for matrix in movements:\n",
        "    #         new_matrix = [\n",
        "    #             matrix[0:4],\n",
        "    #             matrix[4:8],\n",
        "    #             matrix[8:12],\n",
        "    #             [0, 0, 0, 1]\n",
        "    #         ]\n",
        "    #         new_matrix = torch.tensor(new_matrix, dtype=torch.float32)\n",
        "    #         new_movements.append(new_matrix)\n",
        "\n",
        "    #     res_movements = []\n",
        "    #     for i in range(len(new_movements) - 1):\n",
        "    #         T1_inv = torch.linalg.inv(new_movements[i])\n",
        "    #         T_rel = torch.matmul(new_movements[i + 1], T1_inv)\n",
        "    #         res_matrix = T_rel[:3]\n",
        "    #         res_matrix = torch.cat([res_matrix[0], res_matrix[1], res_matrix[2]])\n",
        "    #         res_movements.append(res_matrix)\n",
        "\n",
        "\n",
        "    #     return res_movements\n",
        "\n",
        "    # def transform_mov(movements):\n",
        "    #     res_movements = []\n",
        "    #     for i in range(len(movements)-1):\n",
        "    #         m1 = torch.tensor(movements[i])\n",
        "    #         m2 = torch.tensor(movements[i+1])\n",
        "    #         res = m2-m1\n",
        "    #         res_movements.append(res)\n",
        "    #     return res_movements\n",
        "\n",
        "    def transform_mov(movements):\n",
        "        res_movements = []\n",
        "        steps = [1, 2]\n",
        "        for step in steps:\n",
        "            for i in range(len(movements)-step):\n",
        "                m1 = torch.tensor(movements[i])\n",
        "                m2 = torch.tensor(movements[i + step])\n",
        "                res = m2 - m1\n",
        "                distance = math.sqrt(pow(res[3],2) + pow(res[7],2) + pow(res[11],2))\n",
        "                res_movements.append([distance ])\n",
        "        return res_movements\n",
        "\n",
        "    def list_pair_images(image_folder):\n",
        "        res_images = []\n",
        "        all_image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')])\n",
        "        steps = [1, 2]\n",
        "        for step in steps:\n",
        "            for i in range(len(all_image_files) - step):\n",
        "                image1_path = all_image_files[i]\n",
        "                image2_path = all_image_files[i + step]\n",
        "                res_images.append( (image1_path, image2_path) )\n",
        "\n",
        "        return res_images\n",
        "\n",
        "    # movements = transform_mov(movements)\n",
        "\n",
        "    # Оптимизированный класс Dataset\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_folder, movements, transform= None ):\n",
        "            # Получаем список всех файлов .png и сортируем их\n",
        "            all_image_files = sorted([os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')])\n",
        "            self.image_files = all_image_files\n",
        "            self.movements = movements\n",
        "            self.transform = transform\n",
        "            self.list_images = list_pair_images(image_folder)\n",
        "\n",
        "        def __len__(self):\n",
        "            # Возвращаем минимальную длину между движениями и изображениями - 1\n",
        "            # return min(len(self.movements), len(self.image_files) - 1)\n",
        "            return  len(self.movements)\n",
        "\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            # image1_path = self.image_files[idx]\n",
        "            # image2_path = self.image_files[idx + 1]\n",
        "\n",
        "            image1_path, image2_path = self.list_images[idx]\n",
        "\n",
        "            image1 = Image.open(image1_path).convert('L')\n",
        "            image2 = Image.open(image2_path).convert('L')\n",
        "\n",
        "            x = 100\n",
        "            y = 100\n",
        "            image1_crop = image1.crop( (x, y, x + 320, y + 180) )\n",
        "            image2_crop = image1.crop( (x, y, x + 320, y + 180) )\n",
        "\n",
        "            if self.transform:\n",
        "                image1 = self.transform(image1_crop)\n",
        "                image2 = self.transform(image2_crop)\n",
        "\n",
        "            # movement = self.movements[idx].clone().detach().float()if isinstance(self.movements[idx], torch.Tensor) else torch.tensor(self.movements[idx], dtype=torch.float32)\n",
        "            movement = torch.tensor(self.movements[idx], dtype=torch.float32)\n",
        "            return (image1, image2), movement\n",
        "\n",
        "\n",
        "    # Трансформации для уменьшения использования памяти\n",
        "    transform = transforms.Compose([\n",
        "        # transforms.Grayscale(),\n",
        "        # transforms.Resize((376,1240)),\n",
        "        # transforms.CenterCrop((370,1226)),\n",
        "        # transforms.Resize((180,320)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    def load_dataset(folders):\n",
        "        images, movements = [], []\n",
        "        for image_folder, movements_file in folders:\n",
        "            mov = create_movements(movements_file)\n",
        "            mov = transform_mov(mov)\n",
        "            movements.append(mov)\n",
        "            images.append(image_folder)\n",
        "        return images, movements\n",
        "\n",
        "    train_images, train_movements = load_dataset(train_folders)\n",
        "    train_dataset = []\n",
        "    for index,image_folder in enumerate(train_images):\n",
        "        dataset = ImageDataset(image_folder, train_movements[index], transform= transform)\n",
        "        train_dataset.append(dataset)\n",
        "    train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n",
        "\n",
        "    # arr_gist = np.zeros(100)\n",
        "    # for arr_mov in train_movements:\n",
        "    #     for mov in arr_mov:\n",
        "    #       arr_gist[int(10 * mov[0])] += 1\n",
        "    # h = 0.1\n",
        "    # for x in arr_gist:\n",
        "    #     print(h, '   ', x)\n",
        "    #     h += 0.1\n",
        "\n",
        "    # Загрузка валидационных данных\n",
        "    val_images, val_movements = load_dataset([validation_folder])\n",
        "    val_dataset = ImageDataset(val_images[0], val_movements[0], transform=transform)\n",
        "\n",
        "\n",
        "   # Загрузка тестовых данных\n",
        "    test_images, test_movements = load_dataset([test_folder])\n",
        "    test_dataset = ImageDataset(test_images[0], test_movements[0], transform=transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers=4, pin_memory=True)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "9qgpxoHhJvqr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION"
      ],
      "metadata": {
        "id": "qGxaYV8zJ2ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def compute_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    correct_predictions = 0   # Счетчик корректных предсказаний\n",
        "    total_samples = 0         # Общее количество элементов\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, ((feature1, feature2),targets) in enumerate(data_loader):\n",
        "            feature1 = feature1.to(device)\n",
        "            feature2 = feature2.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predicted_y = model(feature1, feature2)\n",
        "\n",
        "            # Вычисление ошибки\n",
        "            print(predicted_y[0].item(), '   ', targets[0].item())\n",
        "            # print(predicted_y, '      ', targets)\n",
        "            # print(predicted_y[0].item(), predicted_y[1].item(), predicted_y[2].item(), predicted_y[3].item(), predicted_y[4].item(), predicted_y[5].item(), predicted_y[6].item(), predicted_y[7].item())\n",
        "            # print(targets[0].item(), targets[1].item(), targets[2].item(), targets[3].item(), targets[4].item(), targets[5].item(), targets[6].item(), targets[7].item())\n",
        "            loss = criterion(predicted_y, targets)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Проверка критерия качества\n",
        "            relative_difference = torch.abs((predicted_y - targets) / targets)  # Расчет относительного отклонения\n",
        "            valid_predictions = torch.all(relative_difference <= 0.1, dim=1)    # Условие: отклонение <= 10%\n",
        "            correct_predictions += torch.sum(valid_predictions).item()\n",
        "            total_samples = total_samples + targets.size(0)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / num_batches             # Расчет средней ошибки\n",
        "    accuracy = correct_predictions / total_samples  # Расчет доли верных предсказаний\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "uC23AVvUJ5Uo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model ( EfficientNetV2 version 4 )"
      ],
      "metadata": {
        "id": "YRrhzg75J8yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MBConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion_factor, stride, kernel_size= 3):\n",
        "        super(MBConvBlock, self).__init__()\n",
        "\n",
        "        self.use_residual = (in_channels == out_channels) and (stride == 1)\n",
        "        hidden_dim = in_channels * expansion_factor\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # Слой расширения (expansion)\n",
        "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1),\n",
        "            # nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(inplace=True),\n",
        "\n",
        "            # Depthwise свертка\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride,\n",
        "                      padding=kernel_size // 2, groups=hidden_dim),\n",
        "            # nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(inplace=True),\n",
        "\n",
        "            # Сжатие (projection)\n",
        "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1),\n",
        "            # nn.BatchNorm2d(out_channels),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_residual:\n",
        "            return x + self.conv(x)\n",
        "            print(self.conv(x).shape)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "            print(self.conv(x).shape)\n",
        "'''\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # Первый сверточный слой с измененными параметрами\n",
        "        self.conv_stem = nn.Conv2d(2, 32, kernel_size=(6, 10), stride=(2, 3), padding=1)# 184, 407\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU6(inplace=True)\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            # MBConvBlock(32, 64, expansion_factor=1, stride=2), #\n",
        "            MBConvBlock(32, 48, expansion_factor=6, stride=2),# 92, 204\n",
        "            MBConvBlock(48, 64, expansion_factor=6, stride=2),# 46, 102\n",
        "            MBConvBlock(64, 64, expansion_factor=6, stride=1), # 45, 100\n",
        "            MBConvBlock(64, 128, expansion_factor=6, stride=2),# 23, 50\n",
        "            MBConvBlock(128, 128, expansion_factor=6, stride=1),# 22, 45\n",
        "            MBConvBlock(128, 256, expansion_factor=6, stride=2),# 11, 24\n",
        "\n",
        "            # MBConvBlock(256, 256, expansion_factor=6, stride=1),#\n",
        "            nn.Conv2d(256, 256, kernel_size= 4, stride= 2, groups= 256), # 6, 13\n",
        "            nn.Conv2d(256, 256, kernel_size= 1, stride= 1), # 6, 13\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "\n",
        "            MBConvBlock(256, 512, expansion_factor=6, stride=2), # 3, 7\n",
        "\n",
        "            # MBConvBlock(512, 512, expansion_factor=6, stride=2) #\n",
        "            nn.Conv2d(512, 512, kernel_size= 3, stride= 1, groups= 512), # 3, 7\n",
        "            nn.Conv2d(512, 512, kernel_size= 1, stride= 1), # 3, 7\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Dropout2d(p=0.2)\n",
        "\n",
        "        )\n",
        "\n",
        "        # # Глобальный Average Pooling\n",
        "        # self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Полносвязный слой для классификации\n",
        "        self.fc1 = nn.Linear(512 * 4, 16)\n",
        "        self.relu_fc = nn.ReLU(inplace=True)\n",
        "        self.dropout_fc = nn.Dropout(p= 0.4) # Dropout после первого FC слоя\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        x = torch.cat((image1, image2), dim=1)\n",
        "        x = self.relu1(self.bn1(self.conv_stem(x)))\n",
        "        x = self.blocks(x)\n",
        "        # x = self.relu2(self.bn2(self.conv_head(x)))\n",
        "        # x = self.global_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_fc(self.relu_fc(self.fc1(x)))\n",
        "        # x = self.relu_fc(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "'''\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # Первый сверточный слой с измененными параметрами  На входе 180, 320\n",
        "        self.conv_stem = nn.Conv2d(2, 32, kernel_size= 5, stride= 1, padding=1)#\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU6(inplace=True)\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            # MBConvBlock(32, 64, expansion_factor=1, stride=2), #\n",
        "            MBConvBlock(32, 48, expansion_factor=6, stride=2),# 92, 204\n",
        "            MBConvBlock(48, 64, expansion_factor=6, stride=2),# 46, 102\n",
        "            MBConvBlock(64, 64, expansion_factor=6, stride=1), # 45, 100\n",
        "            MBConvBlock(64, 128, expansion_factor=6, stride=2),# 23, 50\n",
        "            MBConvBlock(128, 128, expansion_factor=6, stride=1),# 22, 45\n",
        "            MBConvBlock(128, 256, expansion_factor=6, stride=2),# 11, 24\n",
        "\n",
        "            # MBConvBlock(256, 256, expansion_factor=6, stride=1),#\n",
        "            nn.Conv2d(256, 256, kernel_size= 4, stride= 2, groups= 256), # 6, 13\n",
        "            nn.Conv2d(256, 256, kernel_size= 1, stride= 1), # 6, 13\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            # nn.Dropout2d(p=0.2),\n",
        "\n",
        "            MBConvBlock(256, 512, expansion_factor=6, stride=2), # 3, 7\n",
        "\n",
        "            # MBConvBlock(512, 512, expansion_factor=6, stride=2) #\n",
        "            nn.Conv2d(512, 512, kernel_size= 3, stride= 1, groups= 512), # 3, 7\n",
        "            nn.Conv2d(512, 512, kernel_size= 1, stride= 1), # 3, 7\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            # nn.Dropout2d(p=0.2)\n",
        "\n",
        "        )\n",
        "\n",
        "        # # Глобальный Average Pooling\n",
        "        # self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Полносвязный слой для классификации\n",
        "        self.fc1 = nn.Linear(512 * 3, 16)\n",
        "        self.relu_fc = nn.ReLU(inplace=True)\n",
        "        self.dropout_fc = nn.Dropout(p= 0.2) # Dropout после первого FC слоя\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        x = torch.cat((image1, image2), dim=1)\n",
        "        x = self.relu1(self.conv_stem(x))\n",
        "        x = self.blocks(x)\n",
        "        # x = self.relu2(self.bn2(self.conv_head(x)))\n",
        "        # x = self.global_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_fc(self.relu_fc(self.fc1(x)))\n",
        "        # x = self.relu_fc(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "19VU2yS0J_mN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model ( EfficientNetV2 version 5 )"
      ],
      "metadata": {
        "id": "SKWoEtx52rQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_x = x\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.sigmoid(x) * input_x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channals, out_channals, kernel_size, stride):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channals, out_channals, kernel_size= kernel_size, stride= 1)\n",
        "        self.conv_2 = nn.Conv2d(out_channals, out_channals, kernel_size= kernel_size,\n",
        "                                stride= stride, groups= out_channals)\n",
        "        self.conv_3 =  nn.Conv2d(out_channals, out_channals, kernel_size= 1, stride= 1)\n",
        "        self.relu6 = nn.ReLU6(inplace=True)\n",
        "\n",
        "    def forvard(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.relu6(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # Первый сверточный слой с измененными параметрами  input image 180 X 320\n",
        "        self.conv_stem = nn.Conv2d(2, 32, kernel_size= 20, stride= 1)# 161, 301\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu_1 = nn.ReLU6(inplace=True)\n",
        "        self.spatial_attention = SpatialAttention(kernel_size=7)\n",
        "\n",
        "\n",
        "\n",
        "        self.blocks1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 48, kernel_size= 10, stride= 1),  # 152, 292\n",
        "            nn.Conv2d(48, 48, kernel_size= 10, stride= 2, groups= 48), # 72, 142\n",
        "            nn.Conv2d(48, 48, kernel_size= 1, stride= 1), # 72, 142\n",
        "            # nn.BatchNorm2d(64),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            # nn.Dropout2d(p=0.2),\n",
        "        )\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(48, 64, kernel_size= 10, stride= 1) # 63, 123\n",
        "\n",
        "        self.blocks2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 96, kernel_size= 5, stride= 1), # 59, 119\n",
        "            nn.Conv2d(96, 96, kernel_size= 5, stride= 2, groups= 96), # 28, 58\n",
        "            nn.Conv2d(96, 96, kernel_size= 1, stride= 1), # 28, 58\n",
        "            # nn.BatchNorm2d(128),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            # nn.Dropout2d(p=0.2),\n",
        "        )\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(96, 128, kernel_size= 3, stride= 1) # 26, 56\n",
        "\n",
        "        self.blocks3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 196, kernel_size= 3, stride= 1), # 24, 54\n",
        "            nn.Conv2d(196, 196, kernel_size= 3, stride= 2, groups= 196), # 11, 26\n",
        "            nn.Conv2d(196, 196, kernel_size= 1, stride= 1), # 11, 26\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "        )\n",
        "\n",
        "        self.conv_3 = nn.Conv2d(196, 256, kernel_size= 3, stride= 1) # 9, 24\n",
        "\n",
        "        self.blocks4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size= 3, stride= 1), # 7, 22\n",
        "            nn.Conv2d(384, 384, kernel_size= 3, stride= 2, groups= 384), # 3, 10\n",
        "            nn.Conv2d(384, 384, kernel_size= 1, stride= 1), # 3, 10\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            # nn.Dropout2d(p=0.2),\n",
        "        )\n",
        "\n",
        "        self.conv_4 = nn.Conv2d(384, 512, kernel_size= 3, stride= 1) # 1, 8\n",
        "\n",
        "\n",
        "\n",
        "        # # Глобальный Average Pooling\n",
        "        # self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Полносвязный слой для классификации\n",
        "        self.fc1 = nn.Linear(512 * 10, 32)\n",
        "        self.relu_fc = nn.ReLU(inplace=True)\n",
        "        self.dropout_fc = nn.Dropout(p= 0.2) # Dropout после первого FC слоя\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        x = torch.cat((image1, image2), dim=1)\n",
        "        # x = self.relu1(self.bn1(self.conv_stem(x)))\n",
        "        x = self.relu_1(self.conv_stem(x))\n",
        "        # x = self.spatial_attention(x)\n",
        "        x = self.blocks1(x)\n",
        "        x = self.relu_1(self.conv_1(x))\n",
        "        x = self.blocks2(x)\n",
        "        x = self.relu_1(self.conv_2(x))\n",
        "        x = self.blocks3(x)\n",
        "        x = self.relu_1(self.conv_3(x))\n",
        "        x = self.blocks4(x)\n",
        "        x = self.relu_1(self.conv_4(x))\n",
        "        # x = self.spatial_attention(x)\n",
        "        # x = self.blocks4(x)\n",
        "        # x = self.relu2(self.bn2(self.conv_head(x)))\n",
        "        # x = self.global_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_fc(self.relu_fc(self.fc1(x)))\n",
        "        # x = self.relu_fc(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "G4esr2fD23iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "1JrJ_9UeKJRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель FC\n"
      ],
      "metadata": {
        "id": "H1eNvSk1zkzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.lin_1 = nn.Linear(180 * 320 * 2, 128)\n",
        "        self.relu_fc = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.lin_2 = nn.Linear(128, 16)\n",
        "        self.lin_3 = nn.Linear(16, 1)\n",
        "        self.dropout_fc = nn.Dropout(p= 0.2)\n",
        "\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        # x = torch.cat((image1, image2), dim=1)\n",
        "        im1 = torch.flatten(image1, 1)\n",
        "        im2 = torch.flatten(image1, 1)\n",
        "        x = torch.cat((im1, im2), dim= 1)\n",
        "        x = self.lin_1(x)\n",
        "        # x = self.relu_fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.lin_2(x)\n",
        "        # x = self.relu_fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.lin_3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n"
      ],
      "metadata": {
        "id": "X1v0c0VqzqDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs, last_epoch, train_loader,\n",
        "                validation_loader, test_loader,optimizer, device,scheduler,\n",
        "          checkpoint_dict):\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_loss_list, valid_loss_list = [] ,[], []\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(last_epoch, num_epochs):\n",
        "        loss_train_total = 0\n",
        "        num = 0\n",
        "        model.train()\n",
        "        for batch_idx, ((feature1, feature2), targets) in enumerate(train_loader):\n",
        "            feature1 = feature1.to(device)\n",
        "            feature2 = feature2.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predicted_y = model(feature1,feature2)\n",
        "            loss = criterion(predicted_y, targets)\n",
        "            # loss =  torch.mean(targets - predicted_y)\n",
        "\n",
        "            # loss_train_total += loss.item()\n",
        "            loss_train_total += abs(loss.item())\n",
        "            num += 1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if batch_idx %2000 == 0:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
        "                      f'| Loss: {loss.item():.4f}'\n",
        "                      f'| Learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "                print(predicted_y[0].item(), '   ', targets[0].item())\n",
        "                model.eval()\n",
        "                avg_loss_val, accuracy_val = compute_accuracy(model, validation_loader, device)\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                    f'| Train AVG LOSS: {loss_train_total / num: .4f}  \\n'\n",
        "                    # f'| Train AVG LOSS: {avg_loss_train: .4f} | Accuracy_train: {accuracy_train: .4f} \\n'\n",
        "                    f'| Validation AVG LOSS: {avg_loss_val: .4f} | Accuracy_val: {accuracy_val: .4f} ')\n",
        "                model.train()\n",
        "                # print(predicted_y[0].item(), predicted_y[1].item(), predicted_y[2].item(), predicted_y[3].item(), predicted_y[4].item(), predicted_y[5].item(), predicted_y[6].item(), predicted_y[7].item())\n",
        "                # print(targets[0].item(), targets[1].item(), targets[2].item(), targets[3].item(), targets[4].item(), targets[5].item(), targets[6].item(), targets[7].item())\n",
        "        # scheduler.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            avg_loss_train, accuracy_train = compute_accuracy(model, train_loader, device)\n",
        "            # avg_loss_val, accuracy_val = compute_accuracy(model, validation_loader, device)\n",
        "            # scheduler.step( avg_loss_val)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train AVG LOSS: {loss_train_total / num: .4f}  \\n'\n",
        "                  # f'| Train AVG LOSS: {avg_loss_train: .4f} | Accuracy_train: {accuracy_train: .4f} \\n'\n",
        "                  f'| Validation AVG LOSS: {avg_loss_val: .4f} | Accuracy_val: {accuracy_val: .4f} ')\n",
        "            # train_loss_list.append(avg_loss_train)\n",
        "            valid_loss_list.append(avg_loss_val)\n",
        "\n",
        "        model.train()\n",
        "        scheduler.step()\n",
        "\n",
        "        # checkpoint = {\n",
        "        #     'model_state_dict': model.state_dict(),\n",
        "        #     'optimizer_state_dict': optimizer.state_dict()\n",
        "        # }\n",
        "\n",
        "        checkpoint_dict['state_model'] = model.state_dict()\n",
        "        checkpoint_dict['state_opt'] =  optimizer.state_dict()\n",
        "        checkpoint_dict[ 'state_scheduler'] = scheduler.state_dict()\n",
        "        # checkpoint_dict['train_loss'] = avg_loss_train\n",
        "        checkpoint_dict['val_loss'] = avg_loss_val\n",
        "        # checkpoint_dict['train_acc'] = accuracy_train\n",
        "        checkpoint_dict['val_acc'] =  accuracy_val\n",
        "        checkpoint_dict['EPOCHS'] = num_epochs\n",
        "        checkpoint_dict['current_epoch'] = epoch + 1\n",
        "        checkpoint_dict[ 'learning'] = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        path = directory_path + str(epoch + 1) + '_epoch.pth'\n",
        "        torch.save(checkpoint_dict, path)\n",
        "        # path = '/content/drive/My Drive/checkpoint_model_3.pth'\n",
        "        # torch.save(checkpoint, path)\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    avg_loss_test, accuracy_test = compute_accuracy(model, test_loader,device)\n",
        "    print(f'Test AVG LOSS: {avg_loss_test: .4f} | Accuracy_test: {accuracy_test: .4f}')\n",
        "\n",
        "    return minibatch_loss_list, train_loss_list, valid_loss_list\n"
      ],
      "metadata": {
        "id": "9SRaBtHbKNmQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Описание модели, оптимизатора, шедулера"
      ],
      "metadata": {
        "id": "MuUdJYC9MKvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_model_opt_shed = '''\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.lin_1 = nn.Linear(180 * 320 * 2, 128)\n",
        "        self.relu_fc = nn.ReLU()\n",
        "        self.lin_2 = nn.Linear(128, 16)\n",
        "        self.lin_3 = nn.Linear(16, 1)\n",
        "        self.dropout_fc = nn.Dropout(p= 0.2)\n",
        "\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        # x = torch.cat((image1, image2), dim=1)\n",
        "        im1 = torch.flatten(image1, 1)\n",
        "        im2 = torch.flatten(image1, 1)\n",
        "        x = torch.cat((im1, im2), dim= 1)\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu_fc(x)\n",
        "        x = self.lin_2(x)\n",
        "        x = self.relu_fc(x)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.lin_3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.002)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "j6PJodisMMwj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание библиотеки для хранения сохранения"
      ],
      "metadata": {
        "id": "4xSOkG_fMPvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/drive/My Drive/checpoint/model_5_0/'\n",
        "\n",
        "# Проверка существования директории\n",
        "if not os.path.exists(directory_path):\n",
        "    # Создание директории\n",
        "    os.makedirs(directory_path)\n",
        "    print(f\"Директория {directory_path} была создана.\")\n",
        "else:\n",
        "    print(f\"Директория {directory_path} уже существует.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSGs_h6uMQHe",
        "outputId": "928844d5-4caf-4bd6-b666-106c4c6872e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Директория /content/drive/My Drive/checpoint/model_5_0/ уже существует.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание словаря для сохранения результатов"
      ],
      "metadata": {
        "id": "tjhDwOm6McDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dict = {\n",
        "    'model_description' : txt_model_opt_shed,\n",
        "    'state_model' : None,\n",
        "    'state_opt'   : None,\n",
        "    'state_scheduler' : None,\n",
        "\n",
        "    'train_loss' :None,\n",
        "    'val_loss'   : None,\n",
        "    'best_loss'  : None,\n",
        "    'train_acc'  : None,\n",
        "    'val_acc'    : None,\n",
        "\n",
        "    'EPOCHS'     : None,\n",
        "    'current_epoch' : None,\n",
        "    'learning' : None\n",
        "}"
      ],
      "metadata": {
        "id": "kmWHJSt4Mdut"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN"
      ],
      "metadata": {
        "id": "804ikUOEKR5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "RANDOM_SEED = 123\n",
        "NUM_EPOCHS = 20\n",
        "last_epoch = 0\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Використовується пристрій: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "280cR5eaKTFa",
        "outputId": "d3aa3e16-2843-4a11-af01-c112a5581dd4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Використовується пристрій: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "set_all_seeds(RANDOM_SEED)\n",
        "\n",
        "model = Network()\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0003, weight_decay= 0.001)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "train_loader, validation_loader, test_loader = get_data(batch_size = BATCH_SIZE)\n",
        "scheduler = StepLR(optimizer, step_size = 4, gamma = 0.3)\n",
        "# scheduler = None\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYofTdCMKUMV",
        "outputId": "efd51425-2d54-410d-99b1-24162942ce41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,254,609 trainable parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка словаря из файла\n",
        "path = './3_epoch.pth'\n",
        "checkpoint = torch.load(path)\n",
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "# # Загрузка состояния модели\n",
        "# save_check = checkpoint['optimizer_state_dict']\n",
        "# save_check['lr'] = 0.0003\n",
        "model.load_state_dict( checkpoint['state_model'] )\n",
        "optimizer.load_state_dict( checkpoint['state_opt'] )\n",
        "scheduler.load_state_dict( checkpoint['state_scheduler'] )\n",
        "last_epoch = checkpoint['current_epoch']\n",
        "# # Загрузка состояния оптимизатора\n",
        "# optimizer.load_state_dict(save_check)"
      ],
      "metadata": {
        "id": "RPFTNpOVKXS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if scheduler == None:\n",
        "    scheduler = StepLR(optimizer, step_size = 1, gamma = 1)\n",
        "minibatch_loss, train_acc, valid_acc = train(model = model,\n",
        "            num_epochs = NUM_EPOCHS,\n",
        "            last_epoch = last_epoch,\n",
        "            train_loader = train_loader,\n",
        "            validation_loader = validation_loader,\n",
        "            test_loader = test_loader,\n",
        "            optimizer = optimizer,\n",
        "            device = DEVICE,\n",
        "            scheduler = scheduler,\n",
        "            checkpoint_dict = checkpoint_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7W8JsUqzKXxC",
        "outputId": "e5d27b78-d700-414c-bfbf-34f0461832e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/020 | Batch 0000/40791 | Loss: 0.1536| Learning rate: 0.0003\n",
            "0.0006953999982215464     0.3926427662372589\n",
            "0.0009801366832107306     0.2889880836009979\n",
            "0.0009801366832107306     0.29325538873672485\n",
            "0.0009801366832107306     0.29893848299980164\n",
            "0.0009801366832107306     0.3062071204185486\n",
            "0.0009801366832107306     0.3157193660736084\n",
            "0.0009801367996260524     0.32351788878440857\n",
            "0.0009801366832107306     0.33798491954803467\n",
            "0.0009801366832107306     0.3556867837905884\n",
            "0.0009801366832107306     0.3602379560470581\n",
            "0.0009801366832107306     0.3732980787754059\n",
            "0.0009801366832107306     0.3857421875\n",
            "0.0009801366832107306     0.3946792185306549\n",
            "0.0009801366832107306     0.4027072787284851\n",
            "0.0009801366832107306     0.41747573018074036\n",
            "0.0009801366832107306     0.4288489818572998\n",
            "0.0009801366832107306     0.4427962005138397\n",
            "0.0009801366832107306     0.45316970348358154\n",
            "0.0009801366832107306     0.4688604176044464\n",
            "0.0009801366832107306     0.48217636346817017\n",
            "0.0009801366832107306     0.5026638507843018\n",
            "0.0009801366832107306     0.5048708319664001\n",
            "0.0009801366832107306     0.5254207849502563\n",
            "0.0009801366832107306     0.5360386967658997\n",
            "0.0009801366832107306     0.5500056147575378\n",
            "0.0009801366832107306     0.5605986714363098\n",
            "0.0009801366832107306     0.5689025521278381\n",
            "0.0009801366832107306     0.5808966159820557\n",
            "0.0009801366832107306     0.5896267294883728\n",
            "0.0009801366832107306     0.6068989038467407\n",
            "0.0009801366832107306     0.6160586476325989\n",
            "0.0009801366832107306     0.630285918712616\n",
            "0.0009801366832107306     0.6427117586135864\n",
            "0.0009801366832107306     0.6563873291015625\n",
            "0.0009801366832107306     0.6691455841064453\n",
            "0.0009801366832107306     0.6833941340446472\n",
            "0.0009801366832107306     0.7126710414886475\n",
            "0.0009801366832107306     0.6901860237121582\n",
            "0.0009801366832107306     0.7200950980186462\n",
            "0.0009801366832107306     0.7368292808532715\n",
            "0.0009801366832107306     0.7477290630340576\n",
            "0.0009801366832107306     0.7622151374816895\n",
            "0.0009801366832107306     0.7709970474243164\n",
            "0.0009801366832107306     0.7882239818572998\n",
            "0.0009801366832107306     0.7943480014801025\n",
            "0.0009801366832107306     0.8221784234046936\n",
            "0.0009801366832107306     0.808099091053009\n",
            "0.0009801366832107306     0.8285136222839355\n",
            "0.0009801366832107306     0.8322215676307678\n",
            "0.0009801366832107306     0.843492865562439\n",
            "0.0009801366832107306     0.8509594202041626\n",
            "0.0009801366832107306     0.8642740249633789\n",
            "0.0009801366832107306     0.8713377118110657\n",
            "0.0009801366832107306     0.8883445858955383\n",
            "0.0009801366832107306     0.8989363312721252\n",
            "0.0009801366832107306     0.9085112810134888\n",
            "0.0009801366832107306     0.9184549450874329\n",
            "0.0009801366832107306     0.928745448589325\n",
            "0.0009801366832107306     0.9420591592788696\n",
            "0.0009801366832107306     0.9548971652984619\n",
            "0.0009801366832107306     0.9692944288253784\n",
            "0.0009801366832107306     0.9745809435844421\n",
            "0.0009801366832107306     1.0073877573013306\n",
            "0.0009801366832107306     1.0246025323867798\n",
            "0.0009801366832107306     1.0304665565490723\n",
            "0.0009801366832107306     1.0433317422866821\n",
            "0.0009801366832107306     1.0546492338180542\n",
            "0.0009801366832107306     1.0640820264816284\n",
            "0.0009801366832107306     1.069725751876831\n",
            "0.0009801366832107306     1.0714918375015259\n",
            "0.0009801366832107306     1.0690743923187256\n",
            "0.0009801366832107306     1.0678142309188843\n",
            "0.0009801366832107306     1.0649610757827759\n",
            "0.0009801366832107306     1.076290249824524\n",
            "0.0009801366832107306     1.0761744976043701\n",
            "0.0009801366832107306     1.0792670249938965\n",
            "0.0009801366832107306     1.074942708015442\n",
            "0.0009801366832107306     1.0660825967788696\n",
            "0.0009801366832107306     1.0617265701293945\n",
            "0.0009801366832107306     1.058834195137024\n",
            "0.0009801366832107306     1.0675891637802124\n",
            "0.0009801366832107306     1.0711132287979126\n",
            "0.0009801366832107306     1.0766386985778809\n",
            "0.0009801366832107306     1.0758439302444458\n",
            "0.0009801366832107306     1.0757629871368408\n",
            "0.0009801366832107306     1.0788440704345703\n",
            "0.0009801366832107306     1.0735459327697754\n",
            "0.0009801366832107306     1.0853315591812134\n",
            "0.0009801366832107306     1.0735058784484863\n",
            "0.0009801366832107306     1.082194447517395\n",
            "0.0009801366832107306     1.0848833322525024\n",
            "0.0009801366832107306     1.0908154249191284\n",
            "0.0009801366832107306     1.0924739837646484\n",
            "0.0009801366832107306     1.0953866243362427\n",
            "0.0009801366832107306     1.1124876737594604\n",
            "0.0009801366832107306     1.1087965965270996\n",
            "0.0009801366832107306     1.0957204103469849\n",
            "0.0009801366832107306     1.113807201385498\n",
            "0.0009801366832107306     1.116207480430603\n",
            "0.0009801366832107306     1.1260985136032104\n",
            "0.0009801366832107306     1.1301110982894897\n",
            "0.0009801366832107306     1.1408663988113403\n",
            "0.0009801366832107306     1.1397100687026978\n",
            "0.0009801366832107306     1.1434714794158936\n",
            "0.0009801366832107306     1.1463967561721802\n",
            "0.0009801366832107306     1.151640772819519\n",
            "0.0009801366832107306     1.1586556434631348\n",
            "0.0009801366832107306     1.1644294261932373\n",
            "0.0009801366832107306     1.1693896055221558\n",
            "0.0009801366832107306     1.1702972650527954\n",
            "0.0009801366832107306     1.1704139709472656\n",
            "0.0009801366832107306     1.1845126152038574\n",
            "0.0009801366832107306     1.1903252601623535\n",
            "0.0009801366832107306     1.1913796663284302\n",
            "0.0009801366832107306     1.1940184831619263\n",
            "0.0009801366832107306     1.204353928565979\n",
            "0.0009801366832107306     1.2018492221832275\n",
            "0.0009801366832107306     1.2088654041290283\n",
            "0.0009801366832107306     1.2172154188156128\n",
            "0.0009801366832107306     1.2225850820541382\n",
            "0.0009801366832107306     1.2248666286468506\n",
            "0.0009801366832107306     1.2265307903289795\n",
            "0.0009801366832107306     1.2302669286727905\n",
            "0.0009801366832107306     1.2350656986236572\n",
            "0.0009801366832107306     1.2375905513763428\n",
            "0.0009801366832107306     1.2437800168991089\n",
            "0.0009801366832107306     1.2455532550811768\n",
            "0.0009801366832107306     1.2480695247650146\n",
            "0.0009801366832107306     1.2556250095367432\n",
            "0.0009801366832107306     1.250442624092102\n",
            "0.0009801366832107306     1.2659924030303955\n",
            "0.0009801366832107306     1.268356204032898\n",
            "0.0009801366832107306     1.2719438076019287\n",
            "0.0009801366832107306     1.2729612588882446\n",
            "0.0009801366832107306     1.2711361646652222\n",
            "0.0009801366832107306     1.2749888896942139\n",
            "0.0009801366832107306     1.2741786241531372\n",
            "0.0009801366832107306     1.2774924039840698\n",
            "0.0009801366832107306     1.2666268348693848\n",
            "0.0009801366832107306     1.2726085186004639\n",
            "0.0009801366832107306     1.3121005296707153\n",
            "0.0009801366832107306     1.2182707786560059\n",
            "0.0009801366832107306     1.2548093795776367\n",
            "0.0009801366832107306     1.2500513792037964\n",
            "0.0009801366832107306     1.2475281953811646\n",
            "0.0009801366832107306     1.2363101243972778\n",
            "0.0009801366832107306     1.2138316631317139\n",
            "0.0009801366832107306     1.2029645442962646\n",
            "0.0009801366832107306     1.1992762088775635\n",
            "0.0009801366832107306     1.1884970664978027\n",
            "0.0009801366832107306     1.1769683361053467\n",
            "0.0009801366832107306     1.163327932357788\n",
            "0.0009801366832107306     1.152513027191162\n",
            "0.0009801366832107306     1.1399396657943726\n",
            "0.0009801366832107306     1.133765697479248\n",
            "0.0009801366832107306     1.127394199371338\n",
            "0.0009801366832107306     1.1259206533432007\n",
            "0.0009801366832107306     1.1211851835250854\n",
            "0.0009801366832107306     1.116114854812622\n",
            "0.0009801366832107306     1.1130449771881104\n",
            "0.0009801366832107306     1.1090258359909058\n",
            "0.0009801366832107306     1.1011850833892822\n",
            "0.0009801366832107306     1.0969412326812744\n",
            "0.0009801366832107306     1.0934146642684937\n",
            "0.0009801366832107306     1.0970040559768677\n",
            "0.0009801366832107306     1.0965713262557983\n",
            "0.0009801366832107306     1.0926570892333984\n",
            "0.0009801366832107306     1.0867434740066528\n",
            "0.0009801366832107306     1.0827645063400269\n",
            "0.0009801366832107306     1.0649473667144775\n",
            "0.0009801366832107306     1.0567961931228638\n",
            "0.0009801366832107306     1.0503714084625244\n",
            "0.0009801366832107306     1.0425249338150024\n",
            "0.0009801366832107306     1.0354927778244019\n",
            "0.0009801366832107306     1.0210740566253662\n",
            "0.0009801366832107306     1.01396644115448\n",
            "0.0009801366832107306     1.0035836696624756\n",
            "0.0009801366832107306     0.9946592450141907\n",
            "0.0009801366832107306     0.9884635806083679\n",
            "0.0009801366832107306     0.9799494743347168\n",
            "0.0009801366832107306     0.9707639217376709\n",
            "0.0009801366832107306     0.961600661277771\n",
            "0.0009801366832107306     0.9531290531158447\n",
            "0.0009801366832107306     0.9438698887825012\n",
            "0.0009801366832107306     0.9195473194122314\n",
            "0.0009801366832107306     0.91362065076828\n",
            "0.0009801366832107306     0.8903008103370667\n",
            "0.0009801366832107306     0.886211633682251\n",
            "0.0009801366832107306     0.8757736086845398\n",
            "0.0009801367996260524     0.8760614991188049\n",
            "0.0009801366832107306     0.8691697716712952\n",
            "0.0009801366832107306     0.842631995677948\n",
            "0.0009801366832107306     0.8467301726341248\n",
            "0.0009801366832107306     0.84209805727005\n",
            "0.0009801366832107306     0.8450109362602234\n",
            "0.0009801366832107306     0.8387308120727539\n",
            "0.0009801366832107306     0.840764045715332\n",
            "0.0009801366832107306     0.8409708738327026\n",
            "0.0009801366832107306     0.8380815982818604\n",
            "0.0009801366832107306     0.835748016834259\n",
            "0.0009801366832107306     0.8383721709251404\n",
            "0.0009801366832107306     0.853054404258728\n",
            "0.0009801366832107306     0.8261258006095886\n",
            "0.0009801366832107306     0.8450037240982056\n",
            "0.0009801366832107306     0.8478055596351624\n",
            "0.0009801366832107306     0.856452226638794\n",
            "0.0009801366832107306     0.8565568923950195\n",
            "0.0009801366832107306     0.8718291521072388\n",
            "0.0009801366832107306     0.883141279220581\n",
            "0.0009801367996260524     0.8976335525512695\n",
            "0.0009801366832107306     0.8987714648246765\n",
            "0.0009801366832107306     0.9111951589584351\n",
            "0.0009801366832107306     0.9264386296272278\n",
            "0.0009801366832107306     0.9387354254722595\n",
            "0.0009801366832107306     0.9501258730888367\n",
            "0.0009801366832107306     0.9617332816123962\n",
            "0.0009801366832107306     0.9723095297813416\n",
            "0.0009801366832107306     0.9837411046028137\n",
            "0.0009801366832107306     0.9951539039611816\n",
            "0.0009801366832107306     1.0251423120498657\n",
            "0.0009801366832107306     1.0001128911972046\n",
            "0.0009801366832107306     1.0336687564849854\n",
            "0.0009801366832107306     1.045337200164795\n",
            "0.0009801366832107306     1.0601857900619507\n",
            "0.0009801366832107306     1.0616745948791504\n",
            "0.0009801366832107306     1.078423023223877\n",
            "0.0009801366832107306     1.0929877758026123\n",
            "0.0009801366832107306     1.0988569259643555\n",
            "0.0009801366832107306     1.117553949356079\n",
            "0.0009801366832107306     1.130284309387207\n",
            "0.0009801366832107306     1.1381820440292358\n",
            "0.0009801366832107306     1.1527513265609741\n",
            "0.0009801366832107306     1.16354501247406\n",
            "0.0009801366832107306     1.180557370185852\n",
            "0.0009801366832107306     1.1988993883132935\n",
            "0.0009801366832107306     1.2039684057235718\n",
            "0.0009801366832107306     1.2290284633636475\n",
            "0.0009801366832107306     1.2235310077667236\n",
            "0.0009801366832107306     1.2404433488845825\n",
            "0.0009801366832107306     1.246508002281189\n",
            "0.0009801366832107306     1.2542393207550049\n",
            "0.0009801366832107306     1.2738068103790283\n",
            "0.0009801366832107306     1.2840262651443481\n",
            "0.0009801366832107306     1.287838339805603\n",
            "0.0009801366832107306     1.2987067699432373\n",
            "0.0009801366832107306     1.312967300415039\n",
            "0.0009801366832107306     1.3236124515533447\n",
            "0.0009801366832107306     1.3388434648513794\n",
            "0.0009801366832107306     1.3441979885101318\n",
            "0.0009801366832107306     1.3674328327178955\n",
            "0.0009801366832107306     1.3779631853103638\n",
            "0.0009801366832107306     1.3782446384429932\n",
            "0.0009801366832107306     1.38740873336792\n",
            "0.0009801366832107306     1.400122046470642\n",
            "0.0009801366832107306     1.4082155227661133\n",
            "0.0009801366832107306     1.421875\n",
            "0.0009801366832107306     1.425172209739685\n",
            "0.0009801366832107306     1.439047932624817\n",
            "0.0009801366832107306     1.4490872621536255\n",
            "0.0009801366832107306     1.4461933374404907\n",
            "0.0009801366832107306     1.4710596799850464\n",
            "0.0009801366832107306     1.4680612087249756\n",
            "0.0009801366832107306     1.4876068830490112\n",
            "0.0009801366832107306     1.4869205951690674\n",
            "0.0009801366832107306     1.4897454977035522\n",
            "0.0009801366832107306     1.5038559436798096\n",
            "0.0009801366832107306     1.5013437271118164\n",
            "0.0009801367996260524     1.5070844888687134\n",
            "0.0009801366832107306     1.5083576440811157\n",
            "0.0009801366832107306     1.5147881507873535\n",
            "0.0009801366832107306     1.5195385217666626\n",
            "0.0009801366832107306     1.5283222198486328\n",
            "0.0009801366832107306     1.527254581451416\n",
            "0.0009801366832107306     1.52725088596344\n",
            "0.0009801366832107306     1.530336856842041\n",
            "0.0009801366832107306     1.5389540195465088\n",
            "0.0009801366832107306     1.5374799966812134\n",
            "0.0009801366832107306     1.5450999736785889\n",
            "0.0009801366832107306     1.5408490896224976\n",
            "0.0009801366832107306     1.5401970148086548\n",
            "0.0009801366832107306     1.5271157026290894\n",
            "0.0009801366832107306     1.5146230459213257\n",
            "0.0009801366832107306     1.4988890886306763\n",
            "0.0009801366832107306     1.4816899299621582\n",
            "0.0009801366832107306     1.4839210510253906\n",
            "0.0009801366832107306     1.4674760103225708\n",
            "0.0009801366832107306     1.455836296081543\n",
            "0.0009801366832107306     1.4403789043426514\n",
            "0.0009801366832107306     1.4250843524932861\n",
            "0.0009801366832107306     1.4162144660949707\n",
            "0.0009801366832107306     1.3961355686187744\n",
            "0.0009801366832107306     1.3887566328048706\n",
            "0.0009801366832107306     1.3721507787704468\n",
            "0.0009801366832107306     1.3587340116500854\n",
            "0.0009801366832107306     1.3488463163375854\n",
            "0.0009801366832107306     1.3319995403289795\n",
            "0.0009801366832107306     1.3061436414718628\n",
            "0.0009801366832107306     1.296571135520935\n",
            "0.0009801366832107306     1.2895822525024414\n",
            "0.0009801366832107306     1.2793880701065063\n",
            "0.0009801366832107306     1.2648046016693115\n",
            "0.0009801366832107306     1.2553962469100952\n",
            "0.0009801366832107306     1.2470799684524536\n",
            "0.0009801366832107306     1.238526463508606\n",
            "0.0009801366832107306     1.226161241531372\n",
            "0.0009801366832107306     1.2137906551361084\n",
            "0.0009801366832107306     1.2032493352890015\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0a29d91fc5fc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m minibatch_loss, train_acc, valid_acc = train(model = model,\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0bbeb6de02d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, last_epoch, train_loader, validation_loader, test_loader, optimizer, device, scheduler, checkpoint_dict)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'   '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mavg_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n\u001b[1;32m     40\u001b[0m                     \u001b[0;34mf'| Train AVG LOSS: {loss_train_total / num: .4f}  \\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-917317646b62>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mfeature1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfeature2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}